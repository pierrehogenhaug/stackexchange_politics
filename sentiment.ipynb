{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar\n",
    "from dask.distributed import Client\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import html\n",
    "import numpy as np\n",
    "import psutil\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "posts = pd.concat([pd.read_pickle('./pickle_dataframes/posts1.pkl'),\n",
    "                   pd.read_pickle('./pickle_dataframes/posts2.pkl'),\n",
    "                   pd.read_pickle('./pickle_dataframes/posts3.pkl')]).reset_index(drop=True)\n",
    "\n",
    "questions = pd.read_pickle('./pickle_dataframes/questions_with_topics.pkl')\n",
    "answers = pd.read_pickle('./pickle_dataframes/answers_with_topics.pkl')\n",
    "comments = pd.read_pickle('./pickle_dataframes/comments_with_topics.pkl')\n",
    "\n",
    "users = pd.read_pickle('./pickle_dataframes/users.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comments = comments.sample(frac=0.1, random_state=0)\n",
    "#posts = posts.sample(frac=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users: 38788\n",
      "Questions: 16002\n",
      "Answers: 36090\n",
      "Comments: 184620\n"
     ]
    }
   ],
   "source": [
    "print(f\"Users: {users.shape[0]}\")\n",
    "print(f\"Questions: {questions.shape[0]}\")\n",
    "print(f\"Answers: {answers.shape[0]}\")\n",
    "print(f\"Comments: {comments.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Users on Min. Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2201\n",
      "8879\n"
     ]
    }
   ],
   "source": [
    "# How many posts do we have from missing/deleted users?\n",
    "print(len(posts[posts['OwnerUserId'] == -1]))\n",
    "print(len(comments[comments['UserId']== -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate user activity counts\n",
    "question_count = questions.groupby('OwnerUserId').size().rename('QuestionCount')\n",
    "answer_count = answers.groupby('OwnerUserId').size().rename('AnswerCount')\n",
    "comment_count = comments.groupby('UserId').size().rename('CommentCount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active users: 1464\n"
     ]
    }
   ],
   "source": [
    "# Merge activity counts with user data\n",
    "user_activity = users.merge(question_count, left_on='Id',  right_index=True, how='left') \\\n",
    "                     .merge(answer_count, left_on='Id', right_index=True, how='left') \\\n",
    "                     .merge(comment_count, left_on='Id', right_index=True, how='left') \\\n",
    "                     .fillna({'QuestionCount': 0, 'AnswerCount': 0, 'CommentCount': 0})\n",
    "\n",
    "# Identify and process active users\n",
    "active_users = user_activity.assign(TotalActivity=lambda x: x['QuestionCount'] + x['AnswerCount'] + x['CommentCount'])\n",
    "active_users = active_users[active_users['TotalActivity'] >= 15]\n",
    "active_user_ids = set(active_users['Id'])\n",
    "print(f\"Active users: {active_users.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active Users' Questions:  11435\n",
      "Active Users' Answers:  31672\n",
      "Active Users' Comments:  167141\n"
     ]
    }
   ],
   "source": [
    "active_questions = questions[questions['OwnerUserId'].isin(active_user_ids)]\n",
    "active_answers = answers[answers['OwnerUserId'].isin(active_user_ids)]\n",
    "active_comments = comments[comments['UserId'].isin(active_user_ids)]\n",
    "\n",
    "print(\"Active Users' Questions: \", active_questions.shape[0])\n",
    "print(\"Active Users' Answers: \", active_answers.shape[0])\n",
    "print(\"Active Users' Comments: \", active_comments.shape[0])\n",
    "\n",
    "#active_posts = pd.concat([active_questions, active_answers]).drop_duplicates()\n",
    "#print(\"Active Users' posts: \", active_posts.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have gathered all questions, answers, and comments from Active users, we proceed to our sentiment analysis. \n",
    "\n",
    "If you don't to run the preprocessing, skip straight to the sentiment analysis where we read the preprocessed dataframes from pickle files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify preprocess_text function\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = html.unescape(text)\n",
    "    text = re.sub(r'<[^>]+>|[^a-zA-Z0-9]', ' ', text.lower())\n",
    "    words = [WordNetLemmatizer().lemmatize(word) for word in text.split() if word not in stopwords.words('english')]\n",
    "    text = ' '.join(words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions\n",
    "ddf_questions = dd.from_pandas(active_questions, npartitions=8)\n",
    "ddf_questions['Body_Processed'] = ddf_questions['Body'].map_partitions(lambda df: df.apply(preprocess_text))\n",
    "ddf_questions['Title_Processed'] = ddf_questions['Title'].map_partitions(lambda df: df.apply(preprocess_text))\n",
    "questions_processed = ddf_questions.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answers\n",
    "ddf_answers = dd.from_pandas(active_answers, npartitions=8)\n",
    "ddf_answers['Body_Processed'] = ddf_answers['Body'].map_partitions(lambda df: df.apply(preprocess_text))\n",
    "answers_processed = ddf_answers.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "# Comments\n",
    "ddf_comments = dd.from_pandas(active_comments, npartitions=8)\n",
    "ddf_comments['Text_Processed'] = ddf_comments['Text'].map_partitions(lambda df: df.apply(preprocess_text))\n",
    "comments_processed = ddf_comments.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_processed.to_pickle('./pickle_dataframes/questions_preprocessed.pkl')\n",
    "answers_processed1, answers_processed2 = np.array_split(answers_processed, 2)\n",
    "\n",
    "#answers_processed.to_pickle('./pickle_dataframes/answers_preprocessed.pkl')\n",
    "answers_processed1.to_pickle('./pickle_dataframes/answers_preprocessed1.pkl')\n",
    "answers_processed2.to_pickle('./pickle_dataframes/answers_preprocessed2.pkl')\n",
    "\n",
    "comments_processed.to_pickle('./pickle_dataframes/comments_preprocessed.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the preprocessed dataframes (answers df is split because of size)\n",
    "\n",
    "questions_processed = pd.read_pickle('./pickle_dataframes/questions_preprocessed.pkl')\n",
    "answers_processed = pd.concat([pd.read_pickle('./pickle_dataframes/answers_preprocessed1.pkl'),\n",
    "                   pd.read_pickle('./pickle_dataframes/answers_preprocessed2.pkl')]).reset_index(drop=True)\n",
    "comments_processed = pd.read_pickle('./pickle_dataframes/comments_preprocessed.pkl')\n",
    "\n",
    "# Remove unused columns\n",
    "# questions_processed = questions_processed.drop(columns=['CreationDate', 'LastActivityDate'])\n",
    "# answers_processed = answers_processed.drop(columns=['CreationDate', 'LastActivityDate', 'Title', 'Tags'])\n",
    "# comments_processed = comments_processed.drop(columns=['CreationDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11435\n",
      "31672\n",
      "167141\n"
     ]
    }
   ],
   "source": [
    "print(questions_processed.shape[0])\n",
    "print(answers_processed.shape[0])\n",
    "print(comments_processed.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/phog/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SentimentIntensityAnalyzer once\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to apply sentiment analysis\n",
    "def analyze_sentiment(text):\n",
    "    # Check if the text is missing or NaN, return 0.0 in such cases\n",
    "    if pd.isna(text):\n",
    "        return 0.0\n",
    "    # Ensure the text is encoded as a string\n",
    "    text = str(text)\n",
    "    return sia.polarity_scores(text)['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 5.06 sms\n",
      "[########################################] | 100% Completed | 46.80 ss\n",
      "[########################################] | 100% Completed | 34.46 ss\n"
     ]
    }
   ],
   "source": [
    "# # Convert pandas DataFrame to Dask DataFrame\n",
    "questions_dask = dd.from_pandas(questions_processed, npartitions=8)  # Adjust npartitions based on available memory\n",
    "answers_dask = dd.from_pandas(answers_processed, npartitions=8) \n",
    "comments_dask = dd.from_pandas(comments_processed, npartitions=8)  \n",
    "\n",
    "# Apply sentiment analysis to questions, answers and comments\n",
    "questions_dask['BodySentiment'] = questions_dask['Body'].map(analyze_sentiment)\n",
    "questions_dask['TitleSentiment'] = questions_dask['Title'].map(analyze_sentiment)\n",
    "\n",
    "answers_dask['BodySentiment'] = answers_dask['Body'].map(analyze_sentiment)\n",
    "\n",
    "comments_dask['TextSentiment'] = comments_dask['Text'].map(analyze_sentiment)\n",
    "\n",
    "# Compute results with progress bar\n",
    "with ProgressBar():\n",
    "    questions_result = questions_dask.compute()\n",
    "    answers_result = answers_dask.compute()\n",
    "    comments_result = comments_dask.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_result = answers_result.drop(columns=['Id_y'])\n",
    "answers_result.rename(columns={'Id_x': 'Id'}, inplace=True)\n",
    "\n",
    "questions_result.to_pickle('./pickle_dataframes/questions_with_sentiment.pkl')\n",
    "\n",
    "answers_result1, answers_result2 = np.array_split(answers_result, 2)\n",
    "answers_result1.to_pickle('./pickle_dataframes/answers_with_sentiment1.pkl')\n",
    "answers_result2.to_pickle('./pickle_dataframes/answers_with_sentiment2.pkl')\n",
    "\n",
    "\n",
    "comments_result.to_pickle('./pickle_dataframes/comments_with_sentiment.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_with_sentiment = pd.read_pickle('./pickle_dataframes/questions_with_sentiment.pkl')\n",
    "answers_with_sentiment = pd.concat([pd.read_pickle('./pickle_dataframes/answers_with_sentiment1.pkl'), pd.read_pickle('./pickle_dataframes/answers_with_sentiment2.pkl')]).reset_index(drop=True)\n",
    "comments_with_sentiment = pd.read_pickle('./pickle_dataframes/comments_with_sentiment.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign Attributes to Users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average sentiment for answers\n",
    "avg_question_body_sentiment = questions_result.groupby('OwnerUserId')['BodySentiment'].mean().rename('AvgQuestionBodySentiment')\n",
    "avg_question_title_sentiment = questions_result.groupby('OwnerUserId')['TitleSentiment'].mean().rename('AvgQuestionTitleSentiment')\n",
    "\n",
    "avg_answer_body_sentiment = questions_result.groupby('OwnerUserId')['BodySentiment'].mean().rename('AvgQuestionBodySentiment')\n",
    "\n",
    "avg_comment_sentiment = answers_result.groupby('OwnerUserId')['Sentiment'].mean().rename('AvgCommentSentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Reputation</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>LastAccessDate</th>\n",
       "      <th>Views</th>\n",
       "      <th>UpVotes</th>\n",
       "      <th>DownVotes</th>\n",
       "      <th>QuestionCount</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>CommentCount</th>\n",
       "      <th>TotalActivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-12-04 20:12:06.337</td>\n",
       "      <td>2012-12-04 20:12:06.337</td>\n",
       "      <td>267</td>\n",
       "      <td>5442</td>\n",
       "      <td>6725</td>\n",
       "      <td>881.0</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>8879.0</td>\n",
       "      <td>11080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>315</td>\n",
       "      <td>2012-12-04 20:36:06.517</td>\n",
       "      <td>2021-07-05 18:03:41.037</td>\n",
       "      <td>49</td>\n",
       "      <td>14</td>\n",
       "      <td>58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2777</td>\n",
       "      <td>2012-12-04 20:52:37.450</td>\n",
       "      <td>2022-07-31 22:39:03.850</td>\n",
       "      <td>832</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>5325</td>\n",
       "      <td>2012-12-04 21:37:27.683</td>\n",
       "      <td>2013-12-18 15:57:41.670</td>\n",
       "      <td>427</td>\n",
       "      <td>110</td>\n",
       "      <td>11</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>16227</td>\n",
       "      <td>2012-12-04 21:49:39.360</td>\n",
       "      <td>2015-02-14 02:38:09.917</td>\n",
       "      <td>1449</td>\n",
       "      <td>803</td>\n",
       "      <td>54</td>\n",
       "      <td>36.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>437.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37644</th>\n",
       "      <td>46025</td>\n",
       "      <td>141</td>\n",
       "      <td>2023-03-19 12:16:59.447</td>\n",
       "      <td>2023-06-27 09:27:37.477</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37863</th>\n",
       "      <td>46253</td>\n",
       "      <td>251</td>\n",
       "      <td>2023-04-07 18:35:35.903</td>\n",
       "      <td>2023-07-22 21:32:54.697</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38111</th>\n",
       "      <td>46524</td>\n",
       "      <td>448</td>\n",
       "      <td>2023-05-17 19:13:21.650</td>\n",
       "      <td>2023-08-19 21:16:59.250</td>\n",
       "      <td>100</td>\n",
       "      <td>37</td>\n",
       "      <td>31</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38246</th>\n",
       "      <td>46665</td>\n",
       "      <td>597</td>\n",
       "      <td>2023-06-07 21:14:53.120</td>\n",
       "      <td>2023-08-17 09:54:23.023</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38572</th>\n",
       "      <td>47010</td>\n",
       "      <td>1302</td>\n",
       "      <td>2023-07-28 21:03:58.967</td>\n",
       "      <td>2023-09-02 21:42:41.943</td>\n",
       "      <td>42</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1464 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id  Reputation            CreationDate          LastAccessDate   \n",
       "0         -1           1 2012-12-04 20:12:06.337 2012-12-04 20:12:06.337  \\\n",
       "5          5         315 2012-12-04 20:36:06.517 2021-07-05 18:03:41.037   \n",
       "8          8        2777 2012-12-04 20:52:37.450 2022-07-31 22:39:03.850   \n",
       "18        18        5325 2012-12-04 21:37:27.683 2013-12-18 15:57:41.670   \n",
       "23        23       16227 2012-12-04 21:49:39.360 2015-02-14 02:38:09.917   \n",
       "...      ...         ...                     ...                     ...   \n",
       "37644  46025         141 2023-03-19 12:16:59.447 2023-06-27 09:27:37.477   \n",
       "37863  46253         251 2023-04-07 18:35:35.903 2023-07-22 21:32:54.697   \n",
       "38111  46524         448 2023-05-17 19:13:21.650 2023-08-19 21:16:59.250   \n",
       "38246  46665         597 2023-06-07 21:14:53.120 2023-08-17 09:54:23.023   \n",
       "38572  47010        1302 2023-07-28 21:03:58.967 2023-09-02 21:42:41.943   \n",
       "\n",
       "       Views  UpVotes  DownVotes  QuestionCount  AnswerCount  CommentCount   \n",
       "0        267     5442       6725          881.0       1320.0        8879.0  \\\n",
       "5         49       14         58            0.0          3.0          31.0   \n",
       "8        832       37          5            0.0         13.0          10.0   \n",
       "18       427      110         11           16.0         20.0          65.0   \n",
       "23      1449      803         54           36.0        124.0         277.0   \n",
       "...      ...      ...        ...            ...          ...           ...   \n",
       "37644     50        0          0            2.0          0.0          16.0   \n",
       "37863      6        3          9            0.0          6.0          10.0   \n",
       "38111    100       37         31            8.0          0.0          15.0   \n",
       "38246      3        0          0            2.0          6.0          11.0   \n",
       "38572     42       23          0            1.0         27.0          38.0   \n",
       "\n",
       "       TotalActivity  \n",
       "0            11080.0  \n",
       "5               34.0  \n",
       "8               23.0  \n",
       "18             101.0  \n",
       "23             437.0  \n",
       "...              ...  \n",
       "37644           18.0  \n",
       "37863           16.0  \n",
       "38111           23.0  \n",
       "38246           19.0  \n",
       "38572           66.0  \n",
       "\n",
       "[1464 rows x 11 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge avg_question_body_sentiment\n",
    "users_with_sentiments = users.merge(avg_question_body_sentiment, left_on='Id', right_index=True, how='left')\n",
    "\n",
    "# Merge avg_question_title_sentiment\n",
    "users_with_sentiments = users_with_sentiments.merge(avg_question_title_sentiment, left_on='Id', right_index=True, how='left')\n",
    "\n",
    "# Merge avg_answer_body_sentiment\n",
    "users_with_sentiments = users_with_sentiments.merge(avg_answer_body_sentiment, left_on='Id', right_index=True, how='left')\n",
    "\n",
    "# Merge avg_comment_sentiment\n",
    "users_with_sentiments = users_with_sentiments.merge(avg_comment_sentiment, left_on='Id', right_index=True, how='left')\n",
    "\n",
    "# Fill missing values with 0 or an appropriate default value\n",
    "users_with_sentiments.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate deviation from mean sentiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average scores\n",
    "avg_question_score = questions_result.groupby('OwnerUserId')['Score'].mean().rename('AvgQuestionScore')\n",
    "avg_answer_score = answer_result.groupby('OwnerUserId')['Score'].mean().rename('AvgAnswerScore')\n",
    "avg_comment_score = comments_result.groupby('OwnerUserId')['Score'].mean().rename('AvgCommentScore')\n",
    "\n",
    "# Merge the avg scores into the users DataFrame\n",
    "#users = users.merge(avg_question_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average scores\n",
    "avg_answer_score = active_posts[active_posts['PostTypeId'] == 2].groupby('OwnerUserId')['Score'].mean().rename('AvgAnswerScore')\n",
    "avg_post_score = active_posts[active_posts['PostTypeId'] == 1].groupby('OwnerUserId')['Score'].mean().rename('AvgPostScore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_users = active_users.merge(avg_answer_score, left_on='Id', right_index=True, how='left') \\\n",
    "                           .merge(avg_post_score, left_on='Id', right_index=True, how='left') \\\n",
    "                           .fillna({'AvgAnswerScore': 0, 'AvgPostScore': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_users['AcceptedAnswerFraction'] = active_users['AcceptedAnswerCount'] / active_users['AnswerCount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of accepted answers per user\n",
    "accepted_answers = set(questions_with_topics['OwnerUserId'] > -1)]['AcceptedAnswerId'])\n",
    "accepted_answers_count = posts_qa[posts_qa['Id'].isin(accepted_answers)].groupby('OwnerUserId').size().rename('AcceptedAnswerCount')\n",
    "\n",
    "# Calculate number of accepted answers per user\n",
    "accepted_answers = set(posts_qa[(posts_qa['PostTypeId'] == 1) & (posts_qa['OwnerUserId'] > -1)]['AcceptedAnswerId'])\n",
    "accepted_answers_count = posts_qa[posts_qa['Id'].isin(accepted_answers)].groupby('OwnerUserId').size().rename('AcceptedAnswerCount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comments_result.to_pickle('comments_result.pkl')\n",
    "#posts_result.to_pickle('posts_result.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_sentiment(x):\n",
    "    topic = x['Topic']\n",
    "    if topic == 'None':\n",
    "        return 0\n",
    "    sentiment = x['AvgAnswerSentiment']\n",
    "    return [sentiment if int(val) > 0 else 0 for val in topic]\n",
    "\n",
    "active_user_answers['TopicSentiment'] = active_user_answers.apply(replace_sentiment, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_topic_sentiment(group):\n",
    "    # Extract the 'Topic' column as a list of lists\n",
    "    transposed_topics_sentiment = group['TopicSentiment'].transpose()\n",
    "    \n",
    "    # Calculate the mean for each row\n",
    "    mean_values = transposed_topics_sentiment.apply(lambda x: pd.to_numeric(x, errors='coerce')).mean(axis=0)\n",
    "    \n",
    "    return mean_values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
