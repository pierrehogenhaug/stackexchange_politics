{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from gensim.models import CoherenceModel\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "import gensim\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df_comments1 = pd.read_pickle('./pickle_dataframes/comments1.pkl')\n",
    "df_comments2 = pd.read_pickle('./pickle_dataframes/comments2.pkl')\n",
    "df_comments = pd.concat([df_comments1,df_comments2])\n",
    "df_comments.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_posts1 = pd.read_pickle('./pickle_dataframes/posts1.pkl')\n",
    "df_posts2 = pd.read_pickle('./pickle_dataframes/posts2.pkl')\n",
    "df_posts3 = pd.read_pickle('./pickle_dataframes/posts3.pkl')\n",
    "df_posts = pd.concat([df_posts1, df_posts2, df_posts3])\n",
    "df_posts.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_postlinks = pd.read_pickle('./pickle_dataframes/posts_links.pkl')\n",
    "df_tags = pd.read_pickle('./pickle_dataframes/tags.pkl')\n",
    "df_users = pd.read_pickle('./pickle_dataframes/users.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at our DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PostId</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>UserId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>Is it fair to inquire about the disadvantages ...</td>\n",
       "      <td>2012-12-04 22:00:00.933</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>I could have reformulated the question, but at...</td>\n",
       "      <td>2012-12-04 22:02:37.737</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Source on this? I don't see how it could possi...</td>\n",
       "      <td>2012-12-04 22:10:10.070</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>@Nick122 In a parliamentary system like the No...</td>\n",
       "      <td>2012-12-04 22:14:33.463</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes, but you will give a negative vote by voti...</td>\n",
       "      <td>2012-12-04 22:16:29.437</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  PostId  Score                                               Text  \\\n",
       "0   1       1      9  Is it fair to inquire about the disadvantages ...   \n",
       "1   3       1      3  I could have reformulated the question, but at...   \n",
       "2   7       2      2  Source on this? I don't see how it could possi...   \n",
       "3  13       2      1  @Nick122 In a parliamentary system like the No...   \n",
       "4  15       2      0  Yes, but you will give a negative vote by voti...   \n",
       "\n",
       "             CreationDate  UserId  \n",
       "0 2012-12-04 22:00:00.933      28  \n",
       "1 2012-12-04 22:02:37.737      18  \n",
       "2 2012-12-04 22:10:10.070      45  \n",
       "3 2012-12-04 22:14:33.463      43  \n",
       "4 2012-12-04 22:16:29.437      45  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PostTypeId</th>\n",
       "      <th>ParentId</th>\n",
       "      <th>AcceptedAnswerId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>Body</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>LastActivityDate</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>CommentCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-12-04 21:40:29.743</td>\n",
       "      <td>42</td>\n",
       "      <td>8309</td>\n",
       "      <td>&lt;p&gt;We all know the situation could arise in th...</td>\n",
       "      <td>18</td>\n",
       "      <td>2019-06-29 09:18:38.430</td>\n",
       "      <td>What are the disadvantages of first-past-the-p...</td>\n",
       "      <td>&lt;election&gt;&lt;voting-systems&gt;&lt;first-past-the-post&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>19</td>\n",
       "      <td>2012-12-04 21:53:18.800</td>\n",
       "      <td>26</td>\n",
       "      <td>7832</td>\n",
       "      <td>&lt;p&gt;I've heard that mathematically it can be sh...</td>\n",
       "      <td>21</td>\n",
       "      <td>2017-05-03 13:53:26.063</td>\n",
       "      <td>Why can't voting be fair if there are more tha...</td>\n",
       "      <td>&lt;voting&gt;&lt;political-theory&gt;&lt;voting-systems&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2012-12-04 21:58:11.187</td>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;p&gt;First-past-the-post voting tends to result ...</td>\n",
       "      <td>26</td>\n",
       "      <td>2012-12-04 21:58:11.187</td>\n",
       "      <td>Comment: N/A</td>\n",
       "      <td>Comment: N/A</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2012-12-04 21:58:39.037</td>\n",
       "      <td>47</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;p&gt;Simple plurality voting has very little in ...</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-12-04 22:04:42.767</td>\n",
       "      <td>Comment: N/A</td>\n",
       "      <td>Comment: N/A</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>28</td>\n",
       "      <td>2012-12-04 21:58:47.500</td>\n",
       "      <td>46</td>\n",
       "      <td>68096</td>\n",
       "      <td>&lt;p&gt;Living in a country where mandatory voting ...</td>\n",
       "      <td>18</td>\n",
       "      <td>2019-02-03 17:38:05.237</td>\n",
       "      <td>What are the advantages/disadvantages of a man...</td>\n",
       "      <td>&lt;voting&gt;&lt;voting-systems&gt;</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  PostTypeId  ParentId  AcceptedAnswerId            CreationDate  Score  \\\n",
       "0   1           1        -1                 5 2012-12-04 21:40:29.743     42   \n",
       "1   2           1        -1                19 2012-12-04 21:53:18.800     26   \n",
       "2   4           2         1                -1 2012-12-04 21:58:11.187      7   \n",
       "3   5           2         1                -1 2012-12-04 21:58:39.037     47   \n",
       "4   6           1        -1                28 2012-12-04 21:58:47.500     46   \n",
       "\n",
       "   ViewCount                                               Body  OwnerUserId  \\\n",
       "0       8309  <p>We all know the situation could arise in th...           18   \n",
       "1       7832  <p>I've heard that mathematically it can be sh...           21   \n",
       "2         -1  <p>First-past-the-post voting tends to result ...           26   \n",
       "3         -1  <p>Simple plurality voting has very little in ...            8   \n",
       "4      68096  <p>Living in a country where mandatory voting ...           18   \n",
       "\n",
       "         LastActivityDate                                              Title  \\\n",
       "0 2019-06-29 09:18:38.430  What are the disadvantages of first-past-the-p...   \n",
       "1 2017-05-03 13:53:26.063  Why can't voting be fair if there are more tha...   \n",
       "2 2012-12-04 21:58:11.187                                       Comment: N/A   \n",
       "3 2012-12-04 22:04:42.767                                       Comment: N/A   \n",
       "4 2019-02-03 17:38:05.237  What are the advantages/disadvantages of a man...   \n",
       "\n",
       "                                              Tags  AnswerCount  CommentCount  \n",
       "0  <election><voting-systems><first-past-the-post>            3             3  \n",
       "1       <voting><political-theory><voting-systems>            4             3  \n",
       "2                                     Comment: N/A           -1             1  \n",
       "3                                     Comment: N/A           -1             1  \n",
       "4                         <voting><voting-systems>            8             5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_posts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df = df_posts[df_posts['PostTypeId'] == 1]\n",
    "\n",
    "# questions_sample_df = questions_df.sample(frac=0.25)\n",
    "questions_df = questions_df.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify preprocess_text function\n",
    "def preprocess_text(text, remove_stopwords=False, use_lemmatize=True, use_stemmer=False):\n",
    "    # Remove non-alphanumeric characters and convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text.lower())\n",
    "\n",
    "    words = text.split()\n",
    "    if remove_stopwords:\n",
    "        words = [word for word in words if word not in stopwords.words('english')]\n",
    "    if use_lemmatize:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    elif use_stemmer:  # Apply stemming only if use_stemmer is True\n",
    "        stemmer = PorterStemmer()\n",
    "        words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WandB Timeeee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define apply_lda_and_log function with run_name parameter\n",
    "def apply_lda_and_log(df, remove_stopwords, use_lemmatize, use_stemmer, tags_weighting, run_name):\n",
    "    # Start a new WandB run with the specified name\n",
    "    wandb.init(project=\"stackexchange_politics\", name=run_name)\n",
    "    \n",
    "    # Preprocess Title, Body, and Tags\n",
    "    df['Title'] = df['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize, use_stemmer))\n",
    "    df['Body'] = df['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize, use_stemmer))\n",
    "    df['Tags'] = df['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize, use_stemmer))\n",
    "\n",
    "\n",
    "    # Combine Title, Body, and Tags with specified weight for Tags\n",
    "    # We Keep the original order (title, body, tags) as it reflects the natural flow of information\n",
    "    df['CombinedText'] = df['Title'] + ' ' + df['Body'] + ' ' + (df['Tags'] * tags_weighting)\n",
    "\n",
    "    # Create a Dictionary and Corpus needed for Topic Modeling\n",
    "    words = [doc.split() for doc in df['CombinedText']]\n",
    "    id2word = corpora.Dictionary(words)\n",
    "    corpus = [id2word.doc2bow(text) for text in words]\n",
    "\n",
    "    # Apply TF-IDF\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df['CombinedText'])\n",
    "\n",
    "    # Apply LDA for different numbers of topics\n",
    "    for n_topics in [5, 10, 15, 20]:\n",
    "        lda = LatentDirichletAllocation(n_components=n_topics, random_state=0)\n",
    "        lda.fit(tfidf_matrix)\n",
    "\n",
    "        # Calculate Coherence Score\n",
    "        lda_gensim = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=n_topics, random_state=0)\n",
    "        coherence_model_lda = CoherenceModel(model=lda_gensim, texts=words, dictionary=id2word, coherence='c_v')\n",
    "        coherence_lda = coherence_model_lda.get_coherence()\n",
    "\n",
    "        # Log Coherence and Perplexity Score\n",
    "        wandb.log({\"coherence_score\": coherence_lda, \"perplexity_score\": lda.perplexity(tfidf_matrix)})\n",
    "        \n",
    "        # Extract and log the top words for each topic as a table\n",
    "        feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "        top_words_data = []\n",
    "        for topic_idx, topic in enumerate(lda.components_):\n",
    "            top_words = [feature_names[i] for i in topic.argsort()[:-10 - 1:-1]]\n",
    "            top_words_data.append([f\"Topic {topic_idx}\"] + top_words)\n",
    "\n",
    "        # Create a WandB Table with top words data\n",
    "        columns = [\"Topic\"] + [f\"Word {i+1}\" for i in range(10)]\n",
    "        top_words_table = wandb.Table(data=top_words_data, columns=columns)\n",
    "        \n",
    "        # Log the table to WandB\n",
    "        wandb.log({f\"n_topics_{n_topics}_cleaned_{str(remove_stopwords)}_lemmatize_{str(use_lemmatize)}_weight_{tags_weighting}\": top_words_table})\n",
    "\n",
    "    \n",
    "    # Close WandB run\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define apply_lda_and_log function with run_name parameter\n",
    "def apply_topic_modeling_and_log(df, remove_stopwords, use_lemmatize, use_stemmer, tags_weighting, run_name):\n",
    "    # Start a new WandB run with the specified name\n",
    "    wandb.init(project=\"stackexchange_politics\", entity=\"s223730\", name=run_name)\n",
    "    # Make sure the script runs in the correct WandB project\n",
    "    print(wandb.run.project_name())\n",
    "\n",
    "    # Preprocess Title, Body, and Tags\n",
    "    df['Title'] = df['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize, use_stemmer))\n",
    "    df['Body'] = df['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize, use_stemmer))\n",
    "    df['Tags'] = df['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize, use_stemmer))\n",
    "\n",
    "\n",
    "    # Combine Title, Body, and Tags with specified weight for Tags\n",
    "    # We Keep the original order (title, body, tags) as it reflects the natural flow of information\n",
    "    df['CombinedText'] = df['Title'] + ' ' + df['Body'] + ' ' + (df['Tags'] * tags_weighting)\n",
    "\n",
    "    # Create a Dictionary and Corpus needed for Topic Modeling\n",
    "    words = [doc.split() for doc in df['CombinedText']]\n",
    "    id2word = corpora.Dictionary(words)\n",
    "    corpus = [id2word.doc2bow(text) for text in words]\n",
    "\n",
    "    # Apply TF-IDF\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df['CombinedText'])\n",
    "\n",
    "    # Apply LDA and NMF for different numbers of topics\n",
    "    for n_topics in [5, 10, 15, 20]:\n",
    "        \n",
    "        # LDA\n",
    "        lda = LatentDirichletAllocation(n_components=n_topics, random_state=0)\n",
    "        lda.fit(tfidf_matrix)\n",
    "\n",
    "        # Calculate Coherence Score\n",
    "        lda_gensim = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=n_topics, random_state=0)\n",
    "        coherence_model_lda = CoherenceModel(model=lda_gensim, texts=words, dictionary=id2word, coherence='c_v')\n",
    "        coherence_lda = coherence_model_lda.get_coherence()\n",
    "\n",
    "        # Log Coherence and Perplexity Score\n",
    "        wandb.log({\"coherence_score\": coherence_lda, \"perplexity_score\": lda.perplexity(tfidf_matrix)})\n",
    "        \n",
    "        # Extract and log the top words for each topic as a table\n",
    "        feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "        top_words_data = []\n",
    "        for topic_idx, topic in enumerate(lda.components_):\n",
    "            top_words = [feature_names[i] for i in topic.argsort()[:-10 - 1:-1]]\n",
    "            top_words_data.append([f\"Topic {topic_idx}\"] + top_words)\n",
    "\n",
    "        # Create a WandB Table with top words data\n",
    "        columns = [\"Topic\"] + [f\"Word {i+1}\" for i in range(10)]\n",
    "        top_words_table = wandb.Table(data=top_words_data, columns=columns)\n",
    "        \n",
    "        # Log the table to WandB\n",
    "        wandb.log({f\"n_topics_{n_topics}_cleaned_{str(remove_stopwords)}_lemmatize_{str(use_lemmatize)}_weight_{tags_weighting}\": top_words_table})\n",
    "\n",
    "        # NMF\n",
    "        nmf_model = NMF(n_components=n_topics, random_state=0)\n",
    "        nmf_W = nmf_model.fit_transform(tfidf_matrix)\n",
    "        nmf_H = nmf_model.components_\n",
    "\n",
    "        # Log the top words for each topic for NMF\n",
    "        nmf_top_words_data = []\n",
    "        for topic_idx, topic in enumerate(nmf_H):\n",
    "            top_words = [feature_names[i] for i in topic.argsort()[:-10 - 1:-1]]\n",
    "            nmf_top_words_data.append([f\"Topic {topic_idx}\"] + top_words)\n",
    "\n",
    "        nmf_top_words_table = wandb.Table(data=nmf_top_words_data, columns=columns)\n",
    "        wandb.log({f\"nmf_n_topics_{n_topics}\": nmf_top_words_table})\n",
    "\n",
    "    \n",
    "    # Close WandB run\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running different LDA configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:e0gzqtpc) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8ceb20af8a4ed29696309d9a0001ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">eager-plasma-1</strong> at: <a href='https://wandb.ai/s223730/stackexchange_politics/runs/e0gzqtpc' target=\"_blank\">https://wandb.ai/s223730/stackexchange_politics/runs/e0gzqtpc</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231119_193622-e0gzqtpc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:e0gzqtpc). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f65a2ae8e53438fa35924a41d696c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113162044461609, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/phog/Desktop/cleverThings/socialGraphs23/politics/stackexchange_politics/wandb/run-20231119_193840-ots4yrbl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s223730/stackexchange_politics/runs/ots4yrbl' target=\"_blank\">Baseline_LDA_sample</a></strong> to <a href='https://wandb.ai/s223730/stackexchange_politics' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s223730/stackexchange_politics' target=\"_blank\">https://wandb.ai/s223730/stackexchange_politics</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s223730/stackexchange_politics/runs/ots4yrbl' target=\"_blank\">https://wandb.ai/s223730/stackexchange_politics/runs/ots4yrbl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackexchange_politics\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec569acd31d4bc89d81124b5f83eff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.033 MB of 0.033 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>coherence_score</td><td>▁▇▅█</td></tr><tr><td>perplexity_score</td><td>▁▂▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>coherence_score</td><td>0.28856</td></tr><tr><td>perplexity_score</td><td>2498.03268</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Baseline_LDA_sample</strong> at: <a href='https://wandb.ai/s223730/stackexchange_politics/runs/ots4yrbl' target=\"_blank\">https://wandb.ai/s223730/stackexchange_politics/runs/ots4yrbl</a><br/>Synced 5 W&B file(s), 8 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231119_193840-ots4yrbl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "apply_topic_modeling_and_log(df_posts[df_posts['PostTypeId'] == 1], \n",
    "                  remove_stopwords=False, \n",
    "                  use_lemmatize=False, \n",
    "                  use_stemmer=False,\n",
    "                  tags_weighting=1, \n",
    "                  run_name=\"Baseline_LDA_sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline removed stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48002948630495caa52ca126dd3f4cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011174233800071912, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/phog/Desktop/cleverThings/socialGraphs23/politics/stackexchange_politics/wandb/run-20231119_185008-vlfz84jt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/deeplearning-02456/stackexchange_politics/runs/vlfz84jt' target=\"_blank\">StopwordsRemoved_LDA</a></strong> to <a href='https://wandb.ai/deeplearning-02456/stackexchange_politics' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/deeplearning-02456/stackexchange_politics' target=\"_blank\">https://wandb.ai/deeplearning-02456/stackexchange_politics</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/deeplearning-02456/stackexchange_politics/runs/vlfz84jt' target=\"_blank\">https://wandb.ai/deeplearning-02456/stackexchange_politics/runs/vlfz84jt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_39220/2996056826.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Title'] = df['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n"
     ]
    }
   ],
   "source": [
    "apply_topic_modeling_and_log(df_posts[df_posts['PostTypeId'] == 1], \n",
    "                  remove_stopwords=True, \n",
    "                  use_lemmatize=False, \n",
    "                  use_stemmer=False,\n",
    "                  tags_weighting=1, \n",
    "                  run_name=\"StopwordsRemoved_LDA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removed stopwords tags weight = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_topic_modeling_and_log(df_posts[df_posts['PostTypeId'] == 1], \n",
    "                  remove_stopwords=True, \n",
    "                  use_lemmatize=False, \n",
    "                  use_stemmer=False,\n",
    "                  tags_weighting=2, \n",
    "                  run_name=\"StopwordsRemoved_LDA_TagsWeight2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removed stopwords tags weight = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_topic_modeling_and_log(df_posts[df_posts['PostTypeId'] == 1], \n",
    "                  remove_stopwords=True, \n",
    "                  use_lemmatize=False, \n",
    "                  use_stemmer=False,\n",
    "                  tags_weighting=5, \n",
    "                  run_name=\"StopwordsRemoved_LDA_TagsWeight5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removed stopwords, lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab18f589b2a4e3a99c1dd70d982ee91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011168531010884584, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/phog/Desktop/cleverThings/socialGraphs23/politics/stackexchange_politics/wandb/run-20231119_162740-upvxw34y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/deeplearning-02456/stackexchange_politics/runs/upvxw34y' target=\"_blank\">StopwordsRemoved_Lemmatized_LDA</a></strong> to <a href='https://wandb.ai/deeplearning-02456/stackexchange_politics' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/deeplearning-02456/stackexchange_politics' target=\"_blank\">https://wandb.ai/deeplearning-02456/stackexchange_politics</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/deeplearning-02456/stackexchange_politics/runs/upvxw34y' target=\"_blank\">https://wandb.ai/deeplearning-02456/stackexchange_politics/runs/upvxw34y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_37361/1734285977.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Title'] = df['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_37361/1734285977.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Body'] = df['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_37361/1734285977.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tags'] = df['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_37361/1734285977.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CombinedText'] = df['Title'] + ' ' + df['Body'] + ' ' + (df['Tags'] * tags_weighting)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4223c61b8194131927a6a15eb0e1b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.017 MB of 0.017 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">StopwordsRemoved_Lemmatized_LDA</strong> at: <a href='https://wandb.ai/deeplearning-02456/stackexchange_politics/runs/upvxw34y' target=\"_blank\">https://wandb.ai/deeplearning-02456/stackexchange_politics/runs/upvxw34y</a><br/>Synced 5 W&B file(s), 4 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231119_162740-upvxw34y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "apply_topic_modeling_and_log(df_posts[df_posts['PostTypeId'] == 1], \n",
    "                  remove_stopwords=True, \n",
    "                  use_lemmatize=True, \n",
    "                  use_stemmer=False,\n",
    "                  tags_weighting=1, \n",
    "                  run_name=\"StopwordsRemoved_Lemmatized_LDA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removed stopwords, lemmatized tags weight = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_topic_modeling_and_log(df_posts[df_posts['PostTypeId'] == 1], \n",
    "                  remove_stopwords=True, \n",
    "                  use_lemmatize=True, \n",
    "                  use_stemmer=False,\n",
    "                  tags_weighting=2, \n",
    "                  run_name=\"StopwordsRemoved_Lemmatized_LDA_TagsWeight2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removed stopwords, lemmatized tags weight = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_topic_modeling_and_log(df_posts[df_posts['PostTypeId'] == 1], \n",
    "                  remove_stopwords=True, \n",
    "                  use_lemmatize=True, \n",
    "                  use_stemmer=False,\n",
    "                  tags_weighting=5, \n",
    "                  run_name=\"StopwordsRemoved_Lemmatized_LDA_TagsWeight5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removed stopwords, stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab18f589b2a4e3a99c1dd70d982ee91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011168531010884584, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/phog/Desktop/cleverThings/socialGraphs23/politics/stackexchange_politics/wandb/run-20231119_162740-upvxw34y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/deeplearning-02456/stackexchange_politics/runs/upvxw34y' target=\"_blank\">StopwordsRemoved_Lemmatized_LDA</a></strong> to <a href='https://wandb.ai/deeplearning-02456/stackexchange_politics' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/deeplearning-02456/stackexchange_politics' target=\"_blank\">https://wandb.ai/deeplearning-02456/stackexchange_politics</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/deeplearning-02456/stackexchange_politics/runs/upvxw34y' target=\"_blank\">https://wandb.ai/deeplearning-02456/stackexchange_politics/runs/upvxw34y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_37361/1734285977.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Title'] = df['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_37361/1734285977.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Body'] = df['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_37361/1734285977.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tags'] = df['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_37361/1734285977.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CombinedText'] = df['Title'] + ' ' + df['Body'] + ' ' + (df['Tags'] * tags_weighting)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4223c61b8194131927a6a15eb0e1b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.017 MB of 0.017 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">StopwordsRemoved_Lemmatized_LDA</strong> at: <a href='https://wandb.ai/deeplearning-02456/stackexchange_politics/runs/upvxw34y' target=\"_blank\">https://wandb.ai/deeplearning-02456/stackexchange_politics/runs/upvxw34y</a><br/>Synced 5 W&B file(s), 4 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231119_162740-upvxw34y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "apply_topic_modeling_and_log(df_posts[df_posts['PostTypeId'] == 1], \n",
    "                  remove_stopwords=True, \n",
    "                  use_lemmatize=False, \n",
    "                  use_stemmer=True,\n",
    "                  tags_weighting=1, \n",
    "                  run_name=\"StopwordsRemoved_Stemmed_LDA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removed stopwords, stemmed tags weight = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_topic_modeling_and_log(df_posts[df_posts['PostTypeId'] == 1], \n",
    "                  remove_stopwords=True, \n",
    "                  use_lemmatize=False, \n",
    "                  use_stemmer=True,\n",
    "                  tags_weighting=2, \n",
    "                  run_name=\"StopwordsRemoved_Stemmed_LDA_TagsWeight2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removed stopwords, stemmed tags weight = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_topic_modeling_and_log(df_posts[df_posts['PostTypeId'] == 1], \n",
    "                  remove_stopwords=True, \n",
    "                  use_lemmatize=False, \n",
    "                  use_stemmer=True,\n",
    "                  tags_weighting=5, \n",
    "                  run_name=\"StopwordsRemoved_Stemmed_LDA_TagsWeight5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggestions for Improvements\n",
    "- Adjust StopWords?\n",
    "- **Max Features** (TF-IDF)\n",
    "- **Experiment with N-grams**: Use bi-grams or tri-grams in your TF-IDF vectorization to capture phrases which could be more meaningful than individual words.\n",
    "- **Hyperparameter Tuning**: Tune the parameters of the LDA model, like learning decay and batch size, for potentially better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modelling\n",
    "- TF-IDF\n",
    "    - Adjust `max_features`: Limiting or expanding the number of features (words) included in the TF-IDF matrix can impact topic quality.\n",
    "    - Change `ngram_range`: Including bi-grams or tri-grams (e.g., ngram_range=(1,2)) can sometimes help the model capture more meaningful phrases.\n",
    "\n",
    "- **Clustering to find the optimal number of Topics?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df.to_pickle('questions_cleaned_text.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "Apply Sentiment Analysis on:\n",
    "- Post Level\n",
    "- Sub Post Level\n",
    "- Comment Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Community Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**User-Post-Topic Matrix**: \n",
    "- Create a matrix where rows represent users and columns represent topics. \n",
    "- Each cell contains the count of posts/comments a user has made in a particular topic.\n",
    "    - Post Level: where `PostTypeId` == 1 AND `ParentId` == -1\n",
    "    - Sub Post Level: where `PostTypeId` == 1 AND `ParentId` != -1\n",
    "    - Comment Level: where `PostTypeId` == 2\n",
    "- **Include Post Statistics**\n",
    "    - AcceptedAnswerId\n",
    "    - Score\n",
    "    - ViewCount\n",
    "    - AnswerCount\n",
    "    - CommentCount\n",
    "- **Include Comment Statistics**\n",
    "    - Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clustering Algorithms**\n",
    "- K-Means: Use the user-topic matrix to cluster users. Determine the optimal number of clusters (communities) using the Elbow method or Silhouette score.\n",
    "\n",
    "- Hierarchical Clustering: Useful for understanding the data structure and forming hierarchical communities. Dendrograms can visualize the community structure.\n",
    "\n",
    "- DBSCAN: Good for datasets with noise and clusters of varying densities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Market Basket Analysis**\n",
    "- Association Rules and Apriori Algorithm: \n",
    "    - Treat each user's set of topics as a 'basket'. \n",
    "    - Identify strong rules where the presence of one topic implies the presence of another in a user's posts\n",
    "    - This can highlight topic-based communities.\n",
    "- Frequent Itemsets: \n",
    "    - Identify sets of topics that frequently occur together in users' posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Locality Sensitive Hashing (LSH)**\n",
    "- LSH for Dimension Reduction: \n",
    "    - If the user-topic matrix is very sparse and high-dimensional, LSH can reduce dimensions while preserving the similarity structure. This can make subsequent clustering more effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advanced Techniques**\n",
    "- PCY Algorithm: If you're dealing with very large data, this algorithm efficiently finds frequent itemsets, useful in subsequent association rule mining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Communities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Davies-Bouldin Index**: Evaluate the quality of clusters. \n",
    "- Lower Davies-Bouldin index values signify better clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
