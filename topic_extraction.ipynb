{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from gensim.models import CoherenceModel\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "import gensim\n",
    "import html\n",
    "import itertools\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and merge dataframes\n",
    "comments = pd.concat([pd.read_pickle('./pickle_dataframes/comments1.pkl'),\n",
    "                      pd.read_pickle('./pickle_dataframes/comments2.pkl')]).reset_index(drop=True)\n",
    "\n",
    "posts = pd.concat([pd.read_pickle('./pickle_dataframes/posts1.pkl'),\n",
    "                   pd.read_pickle('./pickle_dataframes/posts2.pkl'),\n",
    "                   pd.read_pickle('./pickle_dataframes/posts3.pkl')]).reset_index(drop=True)\n",
    "\n",
    "users = pd.read_pickle('./pickle_dataframes/users.pkl')\n",
    "postlinks = pd.read_pickle('./pickle_dataframes/posts_links.pkl')\n",
    "tags = pd.read_pickle('./pickle_dataframes/tags.pkl')\n",
    "\n",
    "questions = posts[posts.PostTypeId==1]\n",
    "answers = posts[posts['PostTypeId'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comments = comments.sample(frac=0.1, random_state=0)\n",
    "#posts = posts.sample(frac=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From running various tests we found that the topic modelling method that yielded the best highest coherence score and the lowest perplexity score was:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify preprocess_text function\n",
    "def preprocess_text(text, remove_stopwords=False, use_lemmatize=True):\n",
    "    # Decode HTML entities\n",
    "    text = html.unescape(text)\n",
    "\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "\n",
    "    # Remove non-alphanumeric characters and convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text.lower())\n",
    "\n",
    "    words = text.split()\n",
    "    if remove_stopwords:\n",
    "        words = [word for word in words if word not in stopwords.words('english')]\n",
    "    if use_lemmatize:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define apply_lda_and_log function with run_name parameter\n",
    "def apply_topic_modeling_and_log(df, remove_stopwords, use_lemmatize, tags_weighting, run_name, ngram_range=(1, 1), max_features=1000):\n",
    "\n",
    "    # Initialize dictionaries to store topic distributions\n",
    "    lda_distributions = {}\n",
    "    nmf_distributions = {}\n",
    "\n",
    "    # Preprocess Title, Body, and Tags\n",
    "    df['Title'] = df['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
    "    df['Body'] = df['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
    "    df['Tags'] = df['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
    "\n",
    "\n",
    "    # Combine Title, Body, and Tags with specified weight for Tags\n",
    "    # We Keep the original order (title, body, tags) as it reflects the natural flow of information\n",
    "    df['CombinedText'] = df['Title'] + ' ' + df['Body'] + ' ' + (df['Tags'] * tags_weighting)\n",
    "\n",
    "    # Create a Dictionary and Corpus needed for Topic Modeling\n",
    "    words = [doc.split() for doc in df['CombinedText']]\n",
    "    id2word = corpora.Dictionary(words)\n",
    "    corpus = [id2word.doc2bow(text) for text in words]\n",
    "\n",
    "    # Apply TF-IDF with the specified max_features\n",
    "    # ngram_range=(1, 2) for bi-grams, (1, 3) for tri-grams, and (2, 2) for only bi-grams\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=max_features, ngram_range=ngram_range)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df['CombinedText'])\n",
    "\n",
    "    # Apply LDA and NMF for different numbers of topics\n",
    "    # Prepare a structured dictionary to store results with n_topics as part of the key\n",
    "    all_topics_results = {}\n",
    "    for n_topics in [10, 15, 20, 25]:\n",
    "        \n",
    "        # LDA\n",
    "        lda = LatentDirichletAllocation(n_components=n_topics, random_state=0)\n",
    "        lda.fit(tfidf_matrix)\n",
    "\n",
    "        # Extract Topic Distributions for LDA\n",
    "        lda_topic_distributions = lda.transform(tfidf_matrix)\n",
    "\n",
    "        # Normalize LDA Topic Distributions\n",
    "        lda_normalized = np.array(lda_topic_distributions) / np.sum(lda_topic_distributions, axis=1)[:, None]\n",
    "\n",
    "        # Calculate Coherence Score\n",
    "        lda_gensim = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=n_topics, random_state=0)\n",
    "        coherence_model_lda = CoherenceModel(model=lda_gensim, texts=words, dictionary=id2word, coherence='c_v')\n",
    "        coherence_lda = coherence_model_lda.get_coherence()\n",
    "\n",
    "        # Calculate LDA Perplexity\n",
    "        lda_perplexity = lda.perplexity(tfidf_matrix)\n",
    "\n",
    "        # Extract and log the top words for each topic as a table\n",
    "        feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "        top_words_data = []\n",
    "        for topic_idx, topic in enumerate(lda.components_):\n",
    "            top_words = [feature_names[i] for i in topic.argsort()[:-10 - 1:-1]]\n",
    "            top_words_data.append([f\"Topic {topic_idx}\"] + top_words)\n",
    "\n",
    "        # NMF\n",
    "        nmf_model = NMF(n_components=n_topics, random_state=0)\n",
    "        nmf_W = nmf_model.fit_transform(tfidf_matrix)\n",
    "\n",
    "        # Normalize NMF Topic Distributions (nmf_W is already the topic distribution matrix)\n",
    "        nmf_normalized = np.array(nmf_W) / np.sum(nmf_W, axis=1)[:, None]\n",
    "\n",
    "        nmf_H = nmf_model.components_\n",
    "\n",
    "        # Calculate NMF Reconstruction Error\n",
    "        nmf_reconstruction_error = np.linalg.norm(tfidf_matrix - nmf_W.dot(nmf_H))\n",
    "\n",
    "        # Log the top words for each topic for NMF\n",
    "        nmf_top_words_data = []\n",
    "        for topic_idx, topic in enumerate(nmf_H):\n",
    "            top_words = [feature_names[i] for i in topic.argsort()[:-10 - 1:-1]]\n",
    "            nmf_top_words_data.append([f\"Topic {topic_idx}\"] + top_words)\n",
    "\n",
    "\n",
    "        # Store the results including perplexity and reconstruction error\n",
    "        all_topics_results[f\"{run_name}_n_topics_{n_topics}\"] = {\n",
    "            'lda_normalized': lda_normalized,\n",
    "            'nmf_normalized': nmf_normalized,\n",
    "            'lda_coherence': coherence_lda,\n",
    "            'lda_perplexity': lda_perplexity,\n",
    "            'nmf_reconstruction_error': nmf_reconstruction_error,\n",
    "            'lda_top_words': top_words_data,\n",
    "            'nmf_top_words': nmf_top_words_data\n",
    "        }\n",
    "        \n",
    "\n",
    "\n",
    "    # Return the topic distributions\n",
    "    return all_topics_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Title'] = df['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Body'] = df['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tags'] = df['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CombinedText'] = df['Title'] + ' ' + df['Body'] + ' ' + (df['Tags'] * tags_weighting)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run_remove_True_lemmatize_True_weight_1_ngram_(1, 1)_maxfeat_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Title'] = df['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Body'] = df['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tags'] = df['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CombinedText'] = df['Title'] + ' ' + df['Body'] + ' ' + (df['Tags'] * tags_weighting)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run_remove_True_lemmatize_True_weight_1_ngram_(1, 2)_maxfeat_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Title'] = df['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Body'] = df['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tags'] = df['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CombinedText'] = df['Title'] + ' ' + df['Body'] + ' ' + (df['Tags'] * tags_weighting)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run_remove_True_lemmatize_True_weight_1_ngram_(1, 3)_maxfeat_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Title'] = df['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Body'] = df['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tags'] = df['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CombinedText'] = df['Title'] + ' ' + df['Body'] + ' ' + (df['Tags'] * tags_weighting)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run_remove_True_lemmatize_True_weight_2_ngram_(1, 1)_maxfeat_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Title'] = df['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Body'] = df['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tags'] = df['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CombinedText'] = df['Title'] + ' ' + df['Body'] + ' ' + (df['Tags'] * tags_weighting)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run_remove_True_lemmatize_True_weight_2_ngram_(1, 2)_maxfeat_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Title'] = df['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Body'] = df['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tags'] = df['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CombinedText'] = df['Title'] + ' ' + df['Body'] + ' ' + (df['Tags'] * tags_weighting)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run_remove_True_lemmatize_True_weight_2_ngram_(1, 3)_maxfeat_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Title'] = df['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Body'] = df['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tags'] = df['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CombinedText'] = df['Title'] + ' ' + df['Body'] + ' ' + (df['Tags'] * tags_weighting)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run_remove_True_lemmatize_True_weight_5_ngram_(1, 1)_maxfeat_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Title'] = df['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Body'] = df['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tags'] = df['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CombinedText'] = df['Title'] + ' ' + df['Body'] + ' ' + (df['Tags'] * tags_weighting)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run_remove_True_lemmatize_True_weight_5_ngram_(1, 2)_maxfeat_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Title'] = df['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Body'] = df['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tags'] = df['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CombinedText'] = df['Title'] + ' ' + df['Body'] + ' ' + (df['Tags'] * tags_weighting)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run_remove_True_lemmatize_True_weight_5_ngram_(1, 3)_maxfeat_1000\n"
     ]
    }
   ],
   "source": [
    "# Test various combinations\n",
    "use_lemmatize_options = [True]\n",
    "tags_weighting_options = [1, 2, 5]\n",
    "ngram_range_options = [(1, 1), (1, 2), (1, 3)]\n",
    "max_features_options = [1000]\n",
    "remove_stopwords = True \n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for use_lemmatize, tags_weighting, ngram_range, max_features in itertools.product(use_lemmatize_options, tags_weighting_options, ngram_range_options, max_features_options):\n",
    "    run_name = f\"Run_remove_{remove_stopwords}_lemmatize_{use_lemmatize}_weight_{tags_weighting}_ngram_{ngram_range}_maxfeat_{max_features}\"\n",
    "\n",
    "    topics_results = apply_topic_modeling_and_log(\n",
    "        questions,\n",
    "        remove_stopwords,\n",
    "        use_lemmatize,\n",
    "        tags_weighting, \n",
    "        run_name, \n",
    "        ngram_range, \n",
    "        max_features\n",
    "    )\n",
    "    print(run_name)\n",
    "    all_results.update(topics_results)\n",
    "\n",
    "# save dictionary to person_data.pkl file\n",
    "with open('./pickle_dataframes/all_results.pkl', 'wb') as fp:\n",
    "    pickle.dump(all_results, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best topic modelling technique + parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 LDA:\n",
      "Parameters: Run_remove_True_lemmatize_True_weight_5_ngram_(1, 1)_maxfeat_1000_n_topics_25, Coherence: 0.35796155297262766, Perplexity: 2915.358769222285\n",
      "Parameters: Run_remove_True_lemmatize_True_weight_2_ngram_(1, 1)_maxfeat_1000_n_topics_25, Coherence: 0.35796155297262766, Perplexity: 2915.358769222285\n",
      "Parameters: Run_remove_True_lemmatize_True_weight_5_ngram_(1, 3)_maxfeat_1000_n_topics_25, Coherence: 0.35796155297262766, Perplexity: 2955.353878801326\n",
      "Parameters: Run_remove_True_lemmatize_True_weight_2_ngram_(1, 3)_maxfeat_1000_n_topics_25, Coherence: 0.35796155297262766, Perplexity: 2955.353878801326\n",
      "Parameters: Run_remove_True_lemmatize_True_weight_1_ngram_(1, 3)_maxfeat_1000_n_topics_25, Coherence: 0.35796155297262766, Perplexity: 2955.353878801326\n",
      "\n",
      "Top 5 NMF:\n",
      "Parameters: Run_remove_True_lemmatize_True_weight_5_ngram_(1, 3)_maxfeat_1000_n_topics_25, Reconstruction Error: 115.23001833114516\n",
      "Parameters: Run_remove_True_lemmatize_True_weight_2_ngram_(1, 3)_maxfeat_1000_n_topics_25, Reconstruction Error: 115.23001833114516\n",
      "Parameters: Run_remove_True_lemmatize_True_weight_1_ngram_(1, 3)_maxfeat_1000_n_topics_25, Reconstruction Error: 115.23001833114516\n",
      "Parameters: Run_remove_True_lemmatize_True_weight_5_ngram_(1, 2)_maxfeat_1000_n_topics_25, Reconstruction Error: 115.27500333244927\n",
      "Parameters: Run_remove_True_lemmatize_True_weight_2_ngram_(1, 2)_maxfeat_1000_n_topics_25, Reconstruction Error: 115.27500333244927\n"
     ]
    }
   ],
   "source": [
    "all_results = pd.read_pickle('./pickle_dataframes/all_results.pkl')\n",
    "\n",
    "import heapq\n",
    "\n",
    "# Initialize min-heaps to track the top 5 best scores and parameters for LDA and NMF\n",
    "top_5_lda = []\n",
    "top_5_nmf = []\n",
    "\n",
    "# Iterate through all results\n",
    "for run_name, results in all_results.items():\n",
    "    # Extract LDA and NMF scores\n",
    "    lda_score = (results['lda_coherence'], -results['lda_perplexity'])  # Negative perplexity for min-heap\n",
    "    nmf_score = -results['nmf_reconstruction_error']  # Negative error for min-heap\n",
    "\n",
    "    # Update top 5 LDA\n",
    "    if len(top_5_lda) < 5 or lda_score > top_5_lda[0][0]:\n",
    "        if len(top_5_lda) == 5:\n",
    "            heapq.heappop(top_5_lda)\n",
    "        heapq.heappush(top_5_lda, (lda_score, run_name))\n",
    "\n",
    "    # Update top 5 NMF\n",
    "    if len(top_5_nmf) < 5 or nmf_score > top_5_nmf[0][0]:\n",
    "        if len(top_5_nmf) == 5:\n",
    "            heapq.heappop(top_5_nmf)\n",
    "        heapq.heappush(top_5_nmf, (nmf_score, run_name))\n",
    "\n",
    "# Output top 5 LDA\n",
    "print(\"Top 5 LDA:\")\n",
    "for score, params in sorted(top_5_lda, reverse=True):\n",
    "    print(f\"Parameters: {params}, Coherence: {score[0]}, Perplexity: {-score[1]}\")\n",
    "\n",
    "# Output top 5 NMF\n",
    "print(\"\\nTop 5 NMF:\")\n",
    "for score, params in sorted(top_5_nmf, reverse=True):\n",
    "    print(f\"Parameters: {params}, Reconstruction Error: {-score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the best topic model\n",
    "- Parameters: Run_remove_True_lemmatize_True_weight_2_ngram_(1, 3)_maxfeat_1000_n_topics_20, Coherence: 0.4828223717706496, Perplexity: 1705.171976733514\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/3007364649.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  questions['Title'] = questions['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/3007364649.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  questions['Body'] = questions['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/3007364649.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  questions['Tags'] = questions['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/3007364649.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  questions['CombinedText'] = questions['Title'] + ' ' + questions['Body'] + ' ' + (questions['Tags'] * tags_weighting)\n"
     ]
    }
   ],
   "source": [
    "remove_stopwords = True\n",
    "use_lemmatize = True \n",
    "tags_weighting = 5\n",
    "ngram_range = (1, 2)\n",
    "max_features = 1000\n",
    "n_topics = 25\n",
    "\n",
    "# Apply preprocessing to each column\n",
    "questions['Title'] = questions['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
    "questions['Body'] = questions['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
    "questions['Tags'] = questions['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
    "\n",
    "# Combine Title, Body, and Tags\n",
    "questions['CombinedText'] = questions['Title'] + ' ' + questions['Body'] + ' ' + (questions['Tags'] * tags_weighting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=max_features, ngram_range=ngram_range)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(questions['CombinedText'])\n",
    "\n",
    "# Apply LDA\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, random_state=0)\n",
    "lda.fit(tfidf_matrix)\n",
    "\n",
    "# Assign topics to questions\n",
    "topic_assignments = lda.transform(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign Topic to every question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16002, 16)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions['Topic'] = topic_assignments.argmax(axis=1)\n",
    "questions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign Topic to every answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36090, 18)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df = questions[['Id', 'Topic']]\n",
    "\n",
    "# Merge to assign topics from questions to their answers\n",
    "answers_with_topics = answers.merge(topics_df, left_on='ParentId', right_on='Id', how='left')\n",
    "\n",
    "# Rename the 'Topic' column to something like 'InheritedTopic' to avoid confusion\n",
    "answers_with_topics.rename(columns={'Topic': 'AnswerTopic'}, inplace=True)\n",
    "answers_with_topics.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign Topic to every comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = pd.read_pickle('./pickle_dataframes/questions_with_topics.pkl')\n",
    "answers = pd.read_pickle('./pickle_dataframes/answers_with_topics.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge to assign topics from questions to their answers\n",
    "answers_with_topics = answers.merge(questions[['Id', 'Topic']], left_on='ParentId', right_on='Id', how='left')\n",
    "answers_with_topics.rename(columns={'Topic': 'AnswerTopic'}, inplace=True)\n",
    "\n",
    "# Create sets for faster lookup\n",
    "unique_question_ids = set(questions['Id'].unique())\n",
    "unique_answer_ids = set(answers_with_topics['Id_x'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign topics to comments\n",
    "# Check if the comment is associated with a question\n",
    "question_comments = comments[comments['PostId'].isin(unique_question_ids)]\n",
    "question_comments = question_comments.merge(questions[['Id', 'Topic']], left_on='PostId', right_on='Id', how='left')\n",
    "\n",
    "# Check if the comment is associated with an answer\n",
    "answer_comments = comments[comments['PostId'].isin(unique_answer_ids)]\n",
    "answer_comments = answer_comments.merge(answers_with_topics[['Id_x', 'AnswerTopic']], left_on='PostId', right_on='Id_x', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PostId</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>UserId</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Id_x</th>\n",
       "      <th>AnswerTopic</th>\n",
       "      <th>AnswerTopic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>Therefore, the [Nolan Chart](http://en.wikiped...</td>\n",
       "      <td>2012-12-04 22:24:37.873</td>\n",
       "      <td>37</td>\n",
       "      <td>AnswerTopic    24\n",
       "AnswerTopic    24\n",
       "Name: 2, d...</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>I've found this video to be helpful in underst...</td>\n",
       "      <td>2012-12-04 22:30:13.690</td>\n",
       "      <td>53</td>\n",
       "      <td>AnswerTopic    21\n",
       "AnswerTopic    21\n",
       "Name: 3, d...</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>It is possible (though obviously somewhat comp...</td>\n",
       "      <td>2012-12-04 22:44:13.007</td>\n",
       "      <td>26</td>\n",
       "      <td>AnswerTopic    21\n",
       "AnswerTopic    21\n",
       "Name: 6, d...</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>@Taymon: Can you link to some resource explain...</td>\n",
       "      <td>2012-12-04 22:52:03.133</td>\n",
       "      <td>37</td>\n",
       "      <td>AnswerTopic    21\n",
       "AnswerTopic    21\n",
       "Name: 6, d...</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>The problem is that this only guarantees verif...</td>\n",
       "      <td>2012-12-04 23:01:34.513</td>\n",
       "      <td>18</td>\n",
       "      <td>AnswerTopic    21\n",
       "AnswerTopic    21\n",
       "Name: 6, d...</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118136</th>\n",
       "      <td>351989</td>\n",
       "      <td>81024</td>\n",
       "      <td>0</td>\n",
       "      <td>@Steve Prime age (25-54) LFPR is much higher t...</td>\n",
       "      <td>2023-09-03 04:02:29.193</td>\n",
       "      <td>8016</td>\n",
       "      <td>AnswerTopic    1\n",
       "AnswerTopic    1\n",
       "Name: 36032,...</td>\n",
       "      <td>81024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118137</th>\n",
       "      <td>351990</td>\n",
       "      <td>7798</td>\n",
       "      <td>0</td>\n",
       "      <td>Almost none of the assertions in this answer a...</td>\n",
       "      <td>2023-09-03 04:08:13.630</td>\n",
       "      <td>21362</td>\n",
       "      <td>AnswerTopic    1\n",
       "AnswerTopic    1\n",
       "Name: 2355, ...</td>\n",
       "      <td>7798</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118138</th>\n",
       "      <td>351992</td>\n",
       "      <td>38746</td>\n",
       "      <td>0</td>\n",
       "      <td>The mistake you made is assuming good faith by...</td>\n",
       "      <td>2023-09-03 04:09:13.657</td>\n",
       "      <td>21362</td>\n",
       "      <td>AnswerTopic    1\n",
       "AnswerTopic    1\n",
       "Name: 15864,...</td>\n",
       "      <td>38746</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118139</th>\n",
       "      <td>351994</td>\n",
       "      <td>81024</td>\n",
       "      <td>0</td>\n",
       "      <td>@Steve There has been some per capita GDP prog...</td>\n",
       "      <td>2023-09-03 04:14:38.957</td>\n",
       "      <td>8016</td>\n",
       "      <td>AnswerTopic    1\n",
       "AnswerTopic    1\n",
       "Name: 36032,...</td>\n",
       "      <td>81024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118140</th>\n",
       "      <td>351995</td>\n",
       "      <td>81118</td>\n",
       "      <td>0</td>\n",
       "      <td>Indeed, one might insert the Kennedy quote abo...</td>\n",
       "      <td>2023-09-03 04:33:10.497</td>\n",
       "      <td>18373</td>\n",
       "      <td>AnswerTopic    6\n",
       "AnswerTopic    6\n",
       "Name: 36086,...</td>\n",
       "      <td>81118</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118141 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id  PostId  Score  \\\n",
       "0           19      13     17   \n",
       "1           21      18      2   \n",
       "2           27      22     32   \n",
       "3           31      22      1   \n",
       "4           37      22     10   \n",
       "...        ...     ...    ...   \n",
       "118136  351989   81024      0   \n",
       "118137  351990    7798      0   \n",
       "118138  351992   38746      0   \n",
       "118139  351994   81024      0   \n",
       "118140  351995   81118      0   \n",
       "\n",
       "                                                     Text  \\\n",
       "0       Therefore, the [Nolan Chart](http://en.wikiped...   \n",
       "1       I've found this video to be helpful in underst...   \n",
       "2       It is possible (though obviously somewhat comp...   \n",
       "3       @Taymon: Can you link to some resource explain...   \n",
       "4       The problem is that this only guarantees verif...   \n",
       "...                                                   ...   \n",
       "118136  @Steve Prime age (25-54) LFPR is much higher t...   \n",
       "118137  Almost none of the assertions in this answer a...   \n",
       "118138  The mistake you made is assuming good faith by...   \n",
       "118139  @Steve There has been some per capita GDP prog...   \n",
       "118140  Indeed, one might insert the Kennedy quote abo...   \n",
       "\n",
       "                  CreationDate  UserId  \\\n",
       "0      2012-12-04 22:24:37.873      37   \n",
       "1      2012-12-04 22:30:13.690      53   \n",
       "2      2012-12-04 22:44:13.007      26   \n",
       "3      2012-12-04 22:52:03.133      37   \n",
       "4      2012-12-04 23:01:34.513      18   \n",
       "...                        ...     ...   \n",
       "118136 2023-09-03 04:02:29.193    8016   \n",
       "118137 2023-09-03 04:08:13.630   21362   \n",
       "118138 2023-09-03 04:09:13.657   21362   \n",
       "118139 2023-09-03 04:14:38.957    8016   \n",
       "118140 2023-09-03 04:33:10.497   18373   \n",
       "\n",
       "                                                    Topic   Id_x  AnswerTopic  \\\n",
       "0       AnswerTopic    24\n",
       "AnswerTopic    24\n",
       "Name: 2, d...     13           24   \n",
       "1       AnswerTopic    21\n",
       "AnswerTopic    21\n",
       "Name: 3, d...     18           21   \n",
       "2       AnswerTopic    21\n",
       "AnswerTopic    21\n",
       "Name: 6, d...     22           21   \n",
       "3       AnswerTopic    21\n",
       "AnswerTopic    21\n",
       "Name: 6, d...     22           21   \n",
       "4       AnswerTopic    21\n",
       "AnswerTopic    21\n",
       "Name: 6, d...     22           21   \n",
       "...                                                   ...    ...          ...   \n",
       "118136  AnswerTopic    1\n",
       "AnswerTopic    1\n",
       "Name: 36032,...  81024            1   \n",
       "118137  AnswerTopic    1\n",
       "AnswerTopic    1\n",
       "Name: 2355, ...   7798            1   \n",
       "118138  AnswerTopic    1\n",
       "AnswerTopic    1\n",
       "Name: 15864,...  38746            1   \n",
       "118139  AnswerTopic    1\n",
       "AnswerTopic    1\n",
       "Name: 36032,...  81024            1   \n",
       "118140  AnswerTopic    6\n",
       "AnswerTopic    6\n",
       "Name: 36086,...  81118            6   \n",
       "\n",
       "        AnswerTopic  \n",
       "0                24  \n",
       "1                21  \n",
       "2                21  \n",
       "3                21  \n",
       "4                21  \n",
       "...             ...  \n",
       "118136            1  \n",
       "118137            1  \n",
       "118138            1  \n",
       "118139            1  \n",
       "118140            6  \n",
       "\n",
       "[118141 rows x 10 columns]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id_x</th>\n",
       "      <th>PostId</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>UserId</th>\n",
       "      <th>Topic_x</th>\n",
       "      <th>Id_y</th>\n",
       "      <th>Topic_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>Is it fair to inquire about the disadvantages ...</td>\n",
       "      <td>2012-12-04 22:00:00.933</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>I could have reformulated the question, but at...</td>\n",
       "      <td>2012-12-04 22:02:37.737</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Source on this? I don't see how it could possi...</td>\n",
       "      <td>2012-12-04 22:10:10.070</td>\n",
       "      <td>45</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>@Nick122 In a parliamentary system like the No...</td>\n",
       "      <td>2012-12-04 22:14:33.463</td>\n",
       "      <td>43</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes, but you will give a negative vote by voti...</td>\n",
       "      <td>2012-12-04 22:16:29.437</td>\n",
       "      <td>45</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66474</th>\n",
       "      <td>351981</td>\n",
       "      <td>81095</td>\n",
       "      <td>0</td>\n",
       "      <td>Quite simply, Olaf Scholz will not be around f...</td>\n",
       "      <td>2023-09-03 00:04:31.930</td>\n",
       "      <td>14853</td>\n",
       "      <td>6</td>\n",
       "      <td>81095</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66475</th>\n",
       "      <td>351986</td>\n",
       "      <td>81119</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Or is it because their respective party delib...</td>\n",
       "      <td>2023-09-03 03:53:38.313</td>\n",
       "      <td>14234</td>\n",
       "      <td>21</td>\n",
       "      <td>81119</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66476</th>\n",
       "      <td>351987</td>\n",
       "      <td>81119</td>\n",
       "      <td>0</td>\n",
       "      <td>Also, to clarify, are you asking because of th...</td>\n",
       "      <td>2023-09-03 03:54:01.343</td>\n",
       "      <td>14234</td>\n",
       "      <td>21</td>\n",
       "      <td>81119</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66477</th>\n",
       "      <td>351991</td>\n",
       "      <td>81122</td>\n",
       "      <td>0</td>\n",
       "      <td>Meh, not my DV, but this is going to be tough ...</td>\n",
       "      <td>2023-09-03 04:09:05.587</td>\n",
       "      <td>18373</td>\n",
       "      <td>6</td>\n",
       "      <td>81122</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66478</th>\n",
       "      <td>351993</td>\n",
       "      <td>81121</td>\n",
       "      <td>0</td>\n",
       "      <td>Because most others might not have such funds?...</td>\n",
       "      <td>2023-09-03 04:12:33.097</td>\n",
       "      <td>18373</td>\n",
       "      <td>3</td>\n",
       "      <td>81121</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66479 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id_x  PostId  Score  \\\n",
       "0           1       1      9   \n",
       "1           3       1      3   \n",
       "2           7       2      2   \n",
       "3          13       2      1   \n",
       "4          15       2      0   \n",
       "...       ...     ...    ...   \n",
       "66474  351981   81095      0   \n",
       "66475  351986   81119      0   \n",
       "66476  351987   81119      0   \n",
       "66477  351991   81122      0   \n",
       "66478  351993   81121      0   \n",
       "\n",
       "                                                    Text  \\\n",
       "0      Is it fair to inquire about the disadvantages ...   \n",
       "1      I could have reformulated the question, but at...   \n",
       "2      Source on this? I don't see how it could possi...   \n",
       "3      @Nick122 In a parliamentary system like the No...   \n",
       "4      Yes, but you will give a negative vote by voti...   \n",
       "...                                                  ...   \n",
       "66474  Quite simply, Olaf Scholz will not be around f...   \n",
       "66475  \"Or is it because their respective party delib...   \n",
       "66476  Also, to clarify, are you asking because of th...   \n",
       "66477  Meh, not my DV, but this is going to be tough ...   \n",
       "66478  Because most others might not have such funds?...   \n",
       "\n",
       "                 CreationDate  UserId Topic_x   Id_y  Topic_y  \n",
       "0     2012-12-04 22:00:00.933      28       7      1        7  \n",
       "1     2012-12-04 22:02:37.737      18       7      1        7  \n",
       "2     2012-12-04 22:10:10.070      45      21      2       21  \n",
       "3     2012-12-04 22:14:33.463      43      21      2       21  \n",
       "4     2012-12-04 22:16:29.437      45      21      2       21  \n",
       "...                       ...     ...     ...    ...      ...  \n",
       "66474 2023-09-03 00:04:31.930   14853       6  81095        6  \n",
       "66475 2023-09-03 03:53:38.313   14234      21  81119       21  \n",
       "66476 2023-09-03 03:54:01.343   14234      21  81119       21  \n",
       "66477 2023-09-03 04:09:05.587   18373       6  81122        6  \n",
       "66478 2023-09-03 04:12:33.097   18373       3  81121        3  \n",
       "\n",
       "[66479 rows x 9 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine question and answer comments into one DataFrame\n",
    "comments_with_topics = pd.concat([question_comments, answer_comments])\n",
    "\n",
    "# Fill missing topics for comments associated with answers\n",
    "comments_with_topics['Topic'] = comments_with_topics['Topic'].fillna(comments_with_topics['AnswerTopic'])\n",
    "\n",
    "# Drop unnecessary columns\n",
    "comments_with_topics.drop(['Id_x', 'AnswerTopic'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_with_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_comments = comments[comments['PostId'].isin(unique_question_ids)]\n",
    "answer_comments = comments[comments['PostId'].isin(unique_answer_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign topics to comments\n",
    "def assign_comment_topic(comment):\n",
    "    if comment['PostId'] in unique_question_ids:\n",
    "        return questions.loc[questions['Id'] == comment['PostId'], 'Topic'].iloc[0]\n",
    "    elif comment['PostId'] in unique_answer_ids:\n",
    "        return answers_with_topics.loc[answers_with_topics['Id_x'] == comment['PostId'], 'AnswerTopic'].iloc[0]\n",
    "    else:\n",
    "        return None  # or a default value if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each comment\n",
    "comments['Topic'] = comments.apply(assign_comment_topic, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PostId</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>UserId</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>Is it fair to inquire about the disadvantages ...</td>\n",
       "      <td>2012-12-04 22:00:00.933</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>I could have reformulated the question, but at...</td>\n",
       "      <td>2012-12-04 22:02:37.737</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Source on this? I don't see how it could possi...</td>\n",
       "      <td>2012-12-04 22:10:10.070</td>\n",
       "      <td>45</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>@Nick122 In a parliamentary system like the No...</td>\n",
       "      <td>2012-12-04 22:14:33.463</td>\n",
       "      <td>43</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes, but you will give a negative vote by voti...</td>\n",
       "      <td>2012-12-04 22:16:29.437</td>\n",
       "      <td>45</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184667</th>\n",
       "      <td>351991</td>\n",
       "      <td>81122</td>\n",
       "      <td>0</td>\n",
       "      <td>Meh, not my DV, but this is going to be tough ...</td>\n",
       "      <td>2023-09-03 04:09:05.587</td>\n",
       "      <td>18373</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184668</th>\n",
       "      <td>351992</td>\n",
       "      <td>38746</td>\n",
       "      <td>0</td>\n",
       "      <td>The mistake you made is assuming good faith by...</td>\n",
       "      <td>2023-09-03 04:09:13.657</td>\n",
       "      <td>21362</td>\n",
       "      <td>AnswerTopic    1\n",
       "AnswerTopic    1\n",
       "Name: 15864,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184669</th>\n",
       "      <td>351993</td>\n",
       "      <td>81121</td>\n",
       "      <td>0</td>\n",
       "      <td>Because most others might not have such funds?...</td>\n",
       "      <td>2023-09-03 04:12:33.097</td>\n",
       "      <td>18373</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184670</th>\n",
       "      <td>351994</td>\n",
       "      <td>81024</td>\n",
       "      <td>0</td>\n",
       "      <td>@Steve There has been some per capita GDP prog...</td>\n",
       "      <td>2023-09-03 04:14:38.957</td>\n",
       "      <td>8016</td>\n",
       "      <td>AnswerTopic    1\n",
       "AnswerTopic    1\n",
       "Name: 36032,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184671</th>\n",
       "      <td>351995</td>\n",
       "      <td>81118</td>\n",
       "      <td>0</td>\n",
       "      <td>Indeed, one might insert the Kennedy quote abo...</td>\n",
       "      <td>2023-09-03 04:33:10.497</td>\n",
       "      <td>18373</td>\n",
       "      <td>AnswerTopic    6\n",
       "AnswerTopic    6\n",
       "Name: 36086,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184672 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id  PostId  Score  \\\n",
       "0            1       1      9   \n",
       "1            3       1      3   \n",
       "2            7       2      2   \n",
       "3           13       2      1   \n",
       "4           15       2      0   \n",
       "...        ...     ...    ...   \n",
       "184667  351991   81122      0   \n",
       "184668  351992   38746      0   \n",
       "184669  351993   81121      0   \n",
       "184670  351994   81024      0   \n",
       "184671  351995   81118      0   \n",
       "\n",
       "                                                     Text  \\\n",
       "0       Is it fair to inquire about the disadvantages ...   \n",
       "1       I could have reformulated the question, but at...   \n",
       "2       Source on this? I don't see how it could possi...   \n",
       "3       @Nick122 In a parliamentary system like the No...   \n",
       "4       Yes, but you will give a negative vote by voti...   \n",
       "...                                                   ...   \n",
       "184667  Meh, not my DV, but this is going to be tough ...   \n",
       "184668  The mistake you made is assuming good faith by...   \n",
       "184669  Because most others might not have such funds?...   \n",
       "184670  @Steve There has been some per capita GDP prog...   \n",
       "184671  Indeed, one might insert the Kennedy quote abo...   \n",
       "\n",
       "                  CreationDate  UserId  \\\n",
       "0      2012-12-04 22:00:00.933      28   \n",
       "1      2012-12-04 22:02:37.737      18   \n",
       "2      2012-12-04 22:10:10.070      45   \n",
       "3      2012-12-04 22:14:33.463      43   \n",
       "4      2012-12-04 22:16:29.437      45   \n",
       "...                        ...     ...   \n",
       "184667 2023-09-03 04:09:05.587   18373   \n",
       "184668 2023-09-03 04:09:13.657   21362   \n",
       "184669 2023-09-03 04:12:33.097   18373   \n",
       "184670 2023-09-03 04:14:38.957    8016   \n",
       "184671 2023-09-03 04:33:10.497   18373   \n",
       "\n",
       "                                                    Topic  \n",
       "0                                                       7  \n",
       "1                                                       7  \n",
       "2                                                      21  \n",
       "3                                                      21  \n",
       "4                                                      21  \n",
       "...                                                   ...  \n",
       "184667                                                  6  \n",
       "184668  AnswerTopic    1\n",
       "AnswerTopic    1\n",
       "Name: 15864,...  \n",
       "184669                                                  3  \n",
       "184670  AnswerTopic    1\n",
       "AnswerTopic    1\n",
       "Name: 36032,...  \n",
       "184671  AnswerTopic    6\n",
       "AnswerTopic    6\n",
       "Name: 36086,...  \n",
       "\n",
       "[184672 rows x 7 columns]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many missing users do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "881"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions[questions['OwnerUserId'] == -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1320"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answers[answers['OwnerUserId'] == -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8880"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments[comments['UserId']==-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the posts dataframe with topic assignments\n",
    "#questions.to_pickle('./pickle_dataframes/questions_with_topics.pkl')\n",
    "#answers_with_topics.to_pickle('./pickle_dataframes/answers_with_topics.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
