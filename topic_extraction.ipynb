{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from gensim.models import CoherenceModel\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "import gensim\n",
    "import html\n",
    "import itertools\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and merge dataframes\n",
    "comments = pd.concat([pd.read_pickle('./pickle_dataframes/comments1.pkl'),\n",
    "                      pd.read_pickle('./pickle_dataframes/comments2.pkl')]).reset_index(drop=True)\n",
    "\n",
    "posts = pd.concat([pd.read_pickle('./pickle_dataframes/posts1.pkl'),\n",
    "                   pd.read_pickle('./pickle_dataframes/posts2.pkl'),\n",
    "                   pd.read_pickle('./pickle_dataframes/posts3.pkl')]).reset_index(drop=True)\n",
    "\n",
    "users = pd.read_pickle('./pickle_dataframes/users.pkl')\n",
    "postlinks = pd.read_pickle('./pickle_dataframes/posts_links.pkl')\n",
    "tags = pd.read_pickle('./pickle_dataframes/tags.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = comments.sample(frac=0.1, random_state=0)\n",
    "posts = posts.sample(frac=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From running various tests we found that the topic modelling method that yielded the best highest coherence score and the lowest perplexity score was:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify preprocess_text function\n",
    "def preprocess_text(text, remove_stopwords=False, use_lemmatize=True):\n",
    "    # Decode HTML entities\n",
    "    text = html.unescape(text)\n",
    "\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "\n",
    "    # Remove non-alphanumeric characters and convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text.lower())\n",
    "\n",
    "    words = text.split()\n",
    "    if remove_stopwords:\n",
    "        words = [word for word in words if word not in stopwords.words('english')]\n",
    "    if use_lemmatize:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define apply_lda_and_log function with run_name parameter\n",
    "def apply_topic_modeling_and_log(df, remove_stopwords, use_lemmatize, tags_weighting, run_name, ngram_range=(1, 1), max_features=1000):\n",
    "\n",
    "    # Initialize dictionaries to store topic distributions\n",
    "    lda_distributions = {}\n",
    "    nmf_distributions = {}\n",
    "\n",
    "    # Preprocess Title, Body, and Tags\n",
    "    df['Title'] = df['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
    "    df['Body'] = df['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
    "    df['Tags'] = df['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
    "\n",
    "\n",
    "    # Combine Title, Body, and Tags with specified weight for Tags\n",
    "    # We Keep the original order (title, body, tags) as it reflects the natural flow of information\n",
    "    df['CombinedText'] = df['Title'] + ' ' + df['Body'] + ' ' + (df['Tags'] * tags_weighting)\n",
    "\n",
    "    # Create a Dictionary and Corpus needed for Topic Modeling\n",
    "    words = [doc.split() for doc in df['CombinedText']]\n",
    "    id2word = corpora.Dictionary(words)\n",
    "    corpus = [id2word.doc2bow(text) for text in words]\n",
    "\n",
    "    # Apply TF-IDF with the specified max_features\n",
    "    # ngram_range=(1, 2) for bi-grams, (1, 3) for tri-grams, and (2, 2) for only bi-grams\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=max_features, ngram_range=ngram_range)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df['CombinedText'])\n",
    "\n",
    "    # Apply LDA and NMF for different numbers of topics\n",
    "    # Prepare a structured dictionary to store results with n_topics as part of the key\n",
    "    all_topics_results = {}\n",
    "    for n_topics in [5, 10, 15, 20]:\n",
    "        \n",
    "        # LDA\n",
    "        lda = LatentDirichletAllocation(n_components=n_topics, random_state=0)\n",
    "        lda.fit(tfidf_matrix)\n",
    "\n",
    "        # Extract Topic Distributions for LDA\n",
    "        lda_topic_distributions = lda.transform(tfidf_matrix)\n",
    "\n",
    "        # Normalize LDA Topic Distributions\n",
    "        lda_normalized = np.array(lda_topic_distributions) / np.sum(lda_topic_distributions, axis=1)[:, None]\n",
    "\n",
    "        # Calculate Coherence Score\n",
    "        lda_gensim = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=n_topics, random_state=0)\n",
    "        coherence_model_lda = CoherenceModel(model=lda_gensim, texts=words, dictionary=id2word, coherence='c_v')\n",
    "        coherence_lda = coherence_model_lda.get_coherence()\n",
    "\n",
    "        # Calculate LDA Perplexity\n",
    "        lda_perplexity = lda.perplexity(tfidf_matrix)\n",
    "\n",
    "        # Extract and log the top words for each topic as a table\n",
    "        feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "        top_words_data = []\n",
    "        for topic_idx, topic in enumerate(lda.components_):\n",
    "            top_words = [feature_names[i] for i in topic.argsort()[:-10 - 1:-1]]\n",
    "            top_words_data.append([f\"Topic {topic_idx}\"] + top_words)\n",
    "\n",
    "        # NMF\n",
    "        nmf_model = NMF(n_components=n_topics, random_state=0)\n",
    "        nmf_W = nmf_model.fit_transform(tfidf_matrix)\n",
    "\n",
    "        # Normalize NMF Topic Distributions (nmf_W is already the topic distribution matrix)\n",
    "        nmf_normalized = np.array(nmf_W) / np.sum(nmf_W, axis=1)[:, None]\n",
    "\n",
    "        nmf_H = nmf_model.components_\n",
    "\n",
    "        # Calculate NMF Reconstruction Error\n",
    "        nmf_reconstruction_error = np.linalg.norm(tfidf_matrix - nmf_W.dot(nmf_H))\n",
    "\n",
    "        # Log the top words for each topic for NMF\n",
    "        nmf_top_words_data = []\n",
    "        for topic_idx, topic in enumerate(nmf_H):\n",
    "            top_words = [feature_names[i] for i in topic.argsort()[:-10 - 1:-1]]\n",
    "            nmf_top_words_data.append([f\"Topic {topic_idx}\"] + top_words)\n",
    "\n",
    "\n",
    "        # Store the results including perplexity and reconstruction error\n",
    "        all_topics_results[f\"{run_name}_n_topics_{n_topics}\"] = {\n",
    "            'lda_normalized': lda_normalized,\n",
    "            'nmf_normalized': nmf_normalized,\n",
    "            'lda_coherence': coherence_lda,\n",
    "            'lda_perplexity': lda_perplexity,\n",
    "            'nmf_reconstruction_error': nmf_reconstruction_error,\n",
    "            'lda_top_words': top_words_data,\n",
    "            'nmf_top_words': nmf_top_words_data\n",
    "        }\n",
    "        \n",
    "\n",
    "\n",
    "    # Return the topic distributions\n",
    "    return all_topics_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run_remove_True_lemmatize_True_weight_1_ngram_(1, 1)_maxfeat_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pih\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1692: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run_remove_True_lemmatize_True_weight_1_ngram_(1, 2)_maxfeat_1000\n"
     ]
    }
   ],
   "source": [
    "# Test various combinations\n",
    "use_lemmatize_options = [True]\n",
    "tags_weighting_options = [1, 2, 5]\n",
    "ngram_range_options = [(1, 1), (1, 2), (1, 3)]\n",
    "max_features_options = [1000]\n",
    "remove_stopwords = True \n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for use_lemmatize, tags_weighting, ngram_range, max_features in itertools.product(use_lemmatize_options, tags_weighting_options, ngram_range_options, max_features_options):\n",
    "    run_name = f\"Run_remove_{remove_stopwords}_lemmatize_{use_lemmatize}_weight_{tags_weighting}_ngram_{ngram_range}_maxfeat_{max_features}\"\n",
    "\n",
    "    topics_results = apply_topic_modeling_and_log(\n",
    "        posts, \n",
    "        remove_stopwords, \n",
    "        use_lemmatize, \n",
    "        tags_weighting, \n",
    "        run_name, \n",
    "        ngram_range, \n",
    "        max_features\n",
    "    )\n",
    "    print(run_name)\n",
    "    all_results.update(topics_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best topic modelling technique + parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables to track the best scores and parameters\n",
    "best_coherence = 0\n",
    "best_perplexity = float('inf')\n",
    "best_parameters = None\n",
    "\n",
    "# Iterate through all results\n",
    "for run_name, results in all_results.items():\n",
    "    coherence_lda = results['lda_coherence']\n",
    "    lda_perplexity = results['lda_perplexity']\n",
    "\n",
    "    # Check if this combination has better scores\n",
    "    if coherence_lda > best_coherence and lda_perplexity < best_perplexity:\n",
    "        best_coherence = coherence_lda\n",
    "        best_perplexity = lda_perplexity\n",
    "        best_parameters = run_name\n",
    "\n",
    "# Output the best parameters\n",
    "print(f\"Best Parameters: {best_parameters}\")\n",
    "print(f\"Best Coherence Score: {best_coherence}\")\n",
    "print(f\"Best Perplexity Score: {best_perplexity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign Topic to every post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add functional code \n",
    "# df_posts[\"Topic\"] = df_posts.apply(lambda row : get_post_topic(row['Tags'], sorted_communities), axis=1)\n",
    "# pickle.dump(df_posts, open('./picklefiles/posts_with_topic.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
