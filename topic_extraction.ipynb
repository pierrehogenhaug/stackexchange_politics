{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pih\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.18) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from gensim.models import CoherenceModel\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "import gensim\n",
    "import html\n",
    "import itertools\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and merge dataframes\n",
    "comments = pd.concat([pd.read_pickle('./pickle_dataframes/comments1.pkl'),\n",
    "                      pd.read_pickle('./pickle_dataframes/comments2.pkl')]).reset_index(drop=True)\n",
    "\n",
    "posts = pd.concat([pd.read_pickle('./pickle_dataframes/posts1.pkl'),\n",
    "                   pd.read_pickle('./pickle_dataframes/posts2.pkl'),\n",
    "                   pd.read_pickle('./pickle_dataframes/posts3.pkl')]).reset_index(drop=True)\n",
    "\n",
    "users = pd.read_pickle('./pickle_dataframes/users.pkl')\n",
    "postlinks = pd.read_pickle('./pickle_dataframes/posts_links.pkl')\n",
    "tags = pd.read_pickle('./pickle_dataframes/tags.pkl')\n",
    "\n",
    "questions = posts[posts.PostTypeId==1]\n",
    "answers = posts[posts['PostTypeId'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comments = comments.sample(frac=0.1, random_state=0)\n",
    "#posts = posts.sample(frac=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From running various tests we found that the topic modelling method that yielded the best highest coherence score and the lowest perplexity score was:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify preprocess_text function\n",
    "def preprocess_text(text, remove_stopwords=False, use_lemmatize=True):\n",
    "    # Decode HTML entities\n",
    "    text = html.unescape(text)\n",
    "\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "\n",
    "    # Remove non-alphanumeric characters and convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text.lower())\n",
    "\n",
    "    words = text.split()\n",
    "    if remove_stopwords:\n",
    "        words = [word for word in words if word not in stopwords.words('english')]\n",
    "    if use_lemmatize:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define apply_lda_and_log function with run_name parameter\n",
    "def apply_topic_modeling_and_log(df, remove_stopwords, use_lemmatize, tags_weighting, run_name, ngram_range=(1, 1), max_features=1000):\n",
    "\n",
    "    # Initialize dictionaries to store topic distributions\n",
    "    lda_distributions = {}\n",
    "    nmf_distributions = {}\n",
    "\n",
    "    # Preprocess Title, Body, and Tags\n",
    "    df['Title'] = df['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
    "    df['Body'] = df['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
    "    df['Tags'] = df['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
    "\n",
    "\n",
    "    # Combine Title, Body, and Tags with specified weight for Tags\n",
    "    # We Keep the original order (title, body, tags) as it reflects the natural flow of information\n",
    "    df['CombinedText'] = df['Title'] + ' ' + df['Body'] + ' ' + (df['Tags'] * tags_weighting)\n",
    "\n",
    "    # Create a Dictionary and Corpus needed for Topic Modeling\n",
    "    words = [doc.split() for doc in df['CombinedText']]\n",
    "    id2word = corpora.Dictionary(words)\n",
    "    corpus = [id2word.doc2bow(text) for text in words]\n",
    "\n",
    "    # Apply TF-IDF with the specified max_features\n",
    "    # ngram_range=(1, 2) for bi-grams, (1, 3) for tri-grams, and (2, 2) for only bi-grams\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=max_features, ngram_range=ngram_range)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df['CombinedText'])\n",
    "\n",
    "    # Apply LDA and NMF for different numbers of topics\n",
    "    # Prepare a structured dictionary to store results with n_topics as part of the key\n",
    "    all_topics_results = {}\n",
    "    for n_topics in [10, 15, 20, 25]:\n",
    "        \n",
    "        # LDA\n",
    "        lda = LatentDirichletAllocation(n_components=n_topics, random_state=0)\n",
    "        lda.fit(tfidf_matrix)\n",
    "\n",
    "        # Extract Topic Distributions for LDA\n",
    "        lda_topic_distributions = lda.transform(tfidf_matrix)\n",
    "\n",
    "        # Normalize LDA Topic Distributions\n",
    "        lda_normalized = np.array(lda_topic_distributions) / np.sum(lda_topic_distributions, axis=1)[:, None]\n",
    "\n",
    "        # Calculate Coherence Score\n",
    "        lda_gensim = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=n_topics, random_state=0)\n",
    "        coherence_model_lda = CoherenceModel(model=lda_gensim, texts=words, dictionary=id2word, coherence='c_v')\n",
    "        coherence_lda = coherence_model_lda.get_coherence()\n",
    "\n",
    "        # Calculate LDA Perplexity\n",
    "        lda_perplexity = lda.perplexity(tfidf_matrix)\n",
    "\n",
    "        # Extract and log the top words for each topic as a table\n",
    "        feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "        top_words_data = []\n",
    "        for topic_idx, topic in enumerate(lda.components_):\n",
    "            top_words = [feature_names[i] for i in topic.argsort()[:-10 - 1:-1]]\n",
    "            top_words_data.append([f\"Topic {topic_idx}\"] + top_words)\n",
    "\n",
    "        # NMF\n",
    "        nmf_model = NMF(n_components=n_topics, random_state=0)\n",
    "        nmf_W = nmf_model.fit_transform(tfidf_matrix)\n",
    "\n",
    "        # Normalize NMF Topic Distributions (nmf_W is already the topic distribution matrix)\n",
    "        nmf_normalized = np.array(nmf_W) / np.sum(nmf_W, axis=1)[:, None]\n",
    "\n",
    "        nmf_H = nmf_model.components_\n",
    "\n",
    "        # Calculate NMF Reconstruction Error\n",
    "        nmf_reconstruction_error = np.linalg.norm(tfidf_matrix - nmf_W.dot(nmf_H))\n",
    "\n",
    "        # Log the top words for each topic for NMF\n",
    "        nmf_top_words_data = []\n",
    "        for topic_idx, topic in enumerate(nmf_H):\n",
    "            top_words = [feature_names[i] for i in topic.argsort()[:-10 - 1:-1]]\n",
    "            nmf_top_words_data.append([f\"Topic {topic_idx}\"] + top_words)\n",
    "\n",
    "\n",
    "        # Store the results including perplexity and reconstruction error\n",
    "        all_topics_results[f\"{run_name}_n_topics_{n_topics}\"] = {\n",
    "            'lda_normalized': lda_normalized,\n",
    "            'nmf_normalized': nmf_normalized,\n",
    "            'lda_coherence': coherence_lda,\n",
    "            'lda_perplexity': lda_perplexity,\n",
    "            'nmf_reconstruction_error': nmf_reconstruction_error,\n",
    "            'lda_top_words': top_words_data,\n",
    "            'nmf_top_words': nmf_top_words_data\n",
    "        }\n",
    "        \n",
    "\n",
    "\n",
    "    # Return the topic distributions\n",
    "    return all_topics_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You want to jump straight to the topic modelled DataFrames, don't you?\n",
    "\n",
    "Here you go: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Title'] = df['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Body'] = df['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tags'] = df['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CombinedText'] = df['Title'] + ' ' + df['Body'] + ' ' + (df['Tags'] * tags_weighting)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run_remove_True_lemmatize_True_weight_1_ngram_(1, 1)_maxfeat_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Title'] = df['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Body'] = df['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tags'] = df['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CombinedText'] = df['Title'] + ' ' + df['Body'] + ' ' + (df['Tags'] * tags_weighting)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run_remove_True_lemmatize_True_weight_1_ngram_(1, 2)_maxfeat_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Title'] = df['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Body'] = df['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tags'] = df['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CombinedText'] = df['Title'] + ' ' + df['Body'] + ' ' + (df['Tags'] * tags_weighting)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run_remove_True_lemmatize_True_weight_1_ngram_(1, 3)_maxfeat_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Title'] = df['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Body'] = df['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tags'] = df['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CombinedText'] = df['Title'] + ' ' + df['Body'] + ' ' + (df['Tags'] * tags_weighting)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run_remove_True_lemmatize_True_weight_2_ngram_(1, 1)_maxfeat_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Title'] = df['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Body'] = df['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tags'] = df['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CombinedText'] = df['Title'] + ' ' + df['Body'] + ' ' + (df['Tags'] * tags_weighting)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run_remove_True_lemmatize_True_weight_2_ngram_(1, 2)_maxfeat_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Title'] = df['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Body'] = df['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tags'] = df['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CombinedText'] = df['Title'] + ' ' + df['Body'] + ' ' + (df['Tags'] * tags_weighting)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run_remove_True_lemmatize_True_weight_2_ngram_(1, 3)_maxfeat_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Title'] = df['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Body'] = df['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tags'] = df['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CombinedText'] = df['Title'] + ' ' + df['Body'] + ' ' + (df['Tags'] * tags_weighting)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run_remove_True_lemmatize_True_weight_5_ngram_(1, 1)_maxfeat_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Title'] = df['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Body'] = df['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tags'] = df['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CombinedText'] = df['Title'] + ' ' + df['Body'] + ' ' + (df['Tags'] * tags_weighting)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run_remove_True_lemmatize_True_weight_5_ngram_(1, 2)_maxfeat_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Title'] = df['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Body'] = df['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tags'] = df['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/2122389883.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CombinedText'] = df['Title'] + ' ' + df['Body'] + ' ' + (df['Tags'] * tags_weighting)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run_remove_True_lemmatize_True_weight_5_ngram_(1, 3)_maxfeat_1000\n"
     ]
    }
   ],
   "source": [
    "# Test various combinations\n",
    "use_lemmatize_options = [True]\n",
    "tags_weighting_options = [1, 2, 5]\n",
    "ngram_range_options = [(1, 1), (1, 2), (1, 3)]\n",
    "max_features_options = [1000]\n",
    "remove_stopwords = True \n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for use_lemmatize, tags_weighting, ngram_range, max_features in itertools.product(use_lemmatize_options, tags_weighting_options, ngram_range_options, max_features_options):\n",
    "    run_name = f\"Run_remove_{remove_stopwords}_lemmatize_{use_lemmatize}_weight_{tags_weighting}_ngram_{ngram_range}_maxfeat_{max_features}\"\n",
    "\n",
    "    topics_results = apply_topic_modeling_and_log(\n",
    "        questions,\n",
    "        remove_stopwords,\n",
    "        use_lemmatize,\n",
    "        tags_weighting, \n",
    "        run_name, \n",
    "        ngram_range, \n",
    "        max_features\n",
    "    )\n",
    "    print(run_name)\n",
    "    all_results.update(topics_results)\n",
    "\n",
    "# save dictionary to person_data.pkl file\n",
    "with open('./pickle_dataframes/all_results.pkl', 'wb') as fp:\n",
    "    pickle.dump(all_results, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best topic modelling technique + parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 LDA:\n",
      "Parameters: Run_remove_True_lemmatize_True_weight_5_ngram_(1, 1)_maxfeat_1000_n_topics_25, Coherence: 0.35796155297262766, Perplexity: 2915.358769222285\n",
      "Parameters: Run_remove_True_lemmatize_True_weight_2_ngram_(1, 1)_maxfeat_1000_n_topics_25, Coherence: 0.35796155297262766, Perplexity: 2915.358769222285\n",
      "Parameters: Run_remove_True_lemmatize_True_weight_5_ngram_(1, 3)_maxfeat_1000_n_topics_25, Coherence: 0.35796155297262766, Perplexity: 2955.353878801326\n",
      "Parameters: Run_remove_True_lemmatize_True_weight_2_ngram_(1, 3)_maxfeat_1000_n_topics_25, Coherence: 0.35796155297262766, Perplexity: 2955.353878801326\n",
      "Parameters: Run_remove_True_lemmatize_True_weight_1_ngram_(1, 3)_maxfeat_1000_n_topics_25, Coherence: 0.35796155297262766, Perplexity: 2955.353878801326\n",
      "\n",
      "Top 5 NMF:\n",
      "Parameters: Run_remove_True_lemmatize_True_weight_5_ngram_(1, 3)_maxfeat_1000_n_topics_25, Reconstruction Error: 115.23001833114516\n",
      "Parameters: Run_remove_True_lemmatize_True_weight_2_ngram_(1, 3)_maxfeat_1000_n_topics_25, Reconstruction Error: 115.23001833114516\n",
      "Parameters: Run_remove_True_lemmatize_True_weight_1_ngram_(1, 3)_maxfeat_1000_n_topics_25, Reconstruction Error: 115.23001833114516\n",
      "Parameters: Run_remove_True_lemmatize_True_weight_5_ngram_(1, 2)_maxfeat_1000_n_topics_25, Reconstruction Error: 115.27500333244927\n",
      "Parameters: Run_remove_True_lemmatize_True_weight_2_ngram_(1, 2)_maxfeat_1000_n_topics_25, Reconstruction Error: 115.27500333244927\n"
     ]
    }
   ],
   "source": [
    "all_results = pd.read_pickle('./pickle_dataframes/all_results.pkl')\n",
    "\n",
    "import heapq\n",
    "\n",
    "# Initialize min-heaps to track the top 5 best scores and parameters for LDA and NMF\n",
    "top_5_lda = []\n",
    "top_5_nmf = []\n",
    "\n",
    "# Iterate through all results\n",
    "for run_name, results in all_results.items():\n",
    "    # Extract LDA and NMF scores\n",
    "    lda_score = (results['lda_coherence'], -results['lda_perplexity'])  # Negative perplexity for min-heap\n",
    "    nmf_score = -results['nmf_reconstruction_error']  # Negative error for min-heap\n",
    "\n",
    "    # Update top 5 LDA\n",
    "    if len(top_5_lda) < 5 or lda_score > top_5_lda[0][0]:\n",
    "        if len(top_5_lda) == 5:\n",
    "            heapq.heappop(top_5_lda)\n",
    "        heapq.heappush(top_5_lda, (lda_score, run_name))\n",
    "\n",
    "    # Update top 5 NMF\n",
    "    if len(top_5_nmf) < 5 or nmf_score > top_5_nmf[0][0]:\n",
    "        if len(top_5_nmf) == 5:\n",
    "            heapq.heappop(top_5_nmf)\n",
    "        heapq.heappush(top_5_nmf, (nmf_score, run_name))\n",
    "\n",
    "# Output top 5 LDA\n",
    "print(\"Top 5 LDA:\")\n",
    "for score, params in sorted(top_5_lda, reverse=True):\n",
    "    print(f\"Parameters: {params}, Coherence: {score[0]}, Perplexity: {-score[1]}\")\n",
    "\n",
    "# Output top 5 NMF\n",
    "print(\"\\nTop 5 NMF:\")\n",
    "for score, params in sorted(top_5_nmf, reverse=True):\n",
    "    print(f\"Parameters: {params}, Reconstruction Error: {-score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the best topic model\n",
    "- Parameters: Run_remove_True_lemmatize_True_weight_2_ngram_(1, 3)_maxfeat_1000_n_topics_20, Coherence: 0.4828223717706496, Perplexity: 1705.171976733514\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/3007364649.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  questions['Title'] = questions['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/3007364649.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  questions['Body'] = questions['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/3007364649.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  questions['Tags'] = questions['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
      "/var/folders/t0/tn_njz2x7w1_5n3k_13tz4740000gn/T/ipykernel_31810/3007364649.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  questions['CombinedText'] = questions['Title'] + ' ' + questions['Body'] + ' ' + (questions['Tags'] * tags_weighting)\n"
     ]
    }
   ],
   "source": [
    "remove_stopwords = True\n",
    "use_lemmatize = True \n",
    "tags_weighting = 5\n",
    "ngram_range = (1, 2)\n",
    "max_features = 1000\n",
    "n_topics = 25\n",
    "\n",
    "# Apply preprocessing to each column\n",
    "questions['Title'] = questions['Title'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
    "questions['Body'] = questions['Body'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
    "questions['Tags'] = questions['Tags'].apply(lambda x: preprocess_text(x, remove_stopwords, use_lemmatize))\n",
    "\n",
    "# Combine Title, Body, and Tags\n",
    "questions['CombinedText'] = questions['Title'] + ' ' + questions['Body'] + ' ' + (questions['Tags'] * tags_weighting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=max_features, ngram_range=ngram_range)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(questions['CombinedText'])\n",
    "\n",
    "# Apply LDA\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, random_state=0)\n",
    "lda.fit(tfidf_matrix)\n",
    "\n",
    "# Assign topics to questions\n",
    "topic_assignments = lda.transform(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign Topic to every question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16002, 16)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions['Topic'] = topic_assignments.argmax(axis=1)\n",
    "questions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign Topic to every answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36090, 18)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df = questions[['Id', 'Topic']]\n",
    "\n",
    "# Merge to assign topics from questions to their answers\n",
    "answers_with_topics = answers.merge(topics_df, left_on='ParentId', right_on='Id', how='left')\n",
    "\n",
    "# Rename the 'Topic' column to something like 'InheritedTopic' to avoid confusion\n",
    "answers_with_topics.rename(columns={'Topic': 'AnswerTopic'}, inplace=True)\n",
    "answers_with_topics.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign Topic to every comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184672, 6)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many comments do we have?\n",
    "comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = pd.read_pickle('./pickle_dataframes/questions_with_topics.pkl')\n",
    "answers = pd.read_pickle('./pickle_dataframes/answers_with_topics.pkl')\n",
    "topics_df = questions[['Id', 'Topic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge to assign topics from questions to their answers\n",
    "answers_with_topics = answers.merge(questions[['Id', 'Topic']], left_on='ParentId', right_on='Id', how='left')\n",
    "answers_with_topics.rename(columns={'Topic': 'AnswerTopic'}, inplace=True)\n",
    "\n",
    "# Create sets for faster lookup\n",
    "unique_question_ids = set(questions['Id'].unique())\n",
    "unique_answer_ids = set(answers_with_topics['Id_x'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign topics to comments\n",
    "# Check if the comment is associated with a question\n",
    "question_comments = comments[comments['PostId'].isin(unique_question_ids)]\n",
    "question_comments = question_comments.merge(questions[['Id', 'Topic']], left_on='PostId', right_on='Id', how='left')\n",
    "\n",
    "# Check if the comment is associated with an answer\n",
    "answer_comments = comments[comments['PostId'].isin(unique_answer_ids)]\n",
    "answer_comments = answer_comments.merge(answers_with_topics[['Id_x', 'AnswerTopic']], left_on='PostId', right_on='Id_x', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge and select relevant columns for question comments\n",
    "question_comments_with_topics = question_comments.merge(questions[['Id', 'Topic']], left_on='PostId', right_on='Id', how='left')\n",
    "question_comments_with_topics = question_comments_with_topics[['Id_x', 'PostId', 'Score', 'Text', 'CreationDate', 'UserId', 'Topic_x']]\n",
    "question_comments_with_topics.rename(columns={'Id_x': 'Id', 'Topic_x': 'CommentTopic'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge and select relevant columns for answer comments\n",
    "answer_comments_with_topics = answer_comments.merge(answers_with_topics[['Id_x', 'AnswerTopic']], left_on='PostId', right_on='Id_x', how='left')\n",
    "answer_comments_with_topics = answer_comments_with_topics[['Id', 'PostId', 'Score', 'Text', 'CreationDate', 'UserId', 'AnswerTopic_x']]\n",
    "answer_comments_with_topics = answer_comments_with_topics.iloc[:, :7]\n",
    "answer_comments_with_topics.rename(columns={'Id_x': 'Id', 'AnswerTopic_x': 'CommentTopic'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PostId</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>UserId</th>\n",
       "      <th>CommentTopic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>Is it fair to inquire about the disadvantages ...</td>\n",
       "      <td>2012-12-04 22:00:00.933</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>I could have reformulated the question, but at...</td>\n",
       "      <td>2012-12-04 22:02:37.737</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Source on this? I don't see how it could possi...</td>\n",
       "      <td>2012-12-04 22:10:10.070</td>\n",
       "      <td>45</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>@Nick122 In a parliamentary system like the No...</td>\n",
       "      <td>2012-12-04 22:14:33.463</td>\n",
       "      <td>43</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes, but you will give a negative vote by voti...</td>\n",
       "      <td>2012-12-04 22:16:29.437</td>\n",
       "      <td>45</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  PostId  Score                                               Text   \n",
       "0   1       1      9  Is it fair to inquire about the disadvantages ...  \\\n",
       "1   3       1      3  I could have reformulated the question, but at...   \n",
       "2   7       2      2  Source on this? I don't see how it could possi...   \n",
       "3  13       2      1  @Nick122 In a parliamentary system like the No...   \n",
       "4  15       2      0  Yes, but you will give a negative vote by voti...   \n",
       "\n",
       "             CreationDate  UserId  CommentTopic  \n",
       "0 2012-12-04 22:00:00.933      28             7  \n",
       "1 2012-12-04 22:02:37.737      18             7  \n",
       "2 2012-12-04 22:10:10.070      45            21  \n",
       "3 2012-12-04 22:14:33.463      43            21  \n",
       "4 2012-12-04 22:16:29.437      45            21  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate question and answer comments\n",
    "all_comments_with_topics = pd.concat([question_comments_with_topics, answer_comments_with_topics], ignore_index=True)\n",
    "all_comments_with_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments_with_topics.CommentTopic.value_counts().sum()\n",
    "\n",
    "# Only 50 columns did not have either a corresponding question or answer\n",
    "# Let's see which comments it was\n",
    "comments_without_question_or_answer = comments[~comments['PostId'].isin(unique_question_ids) & ~comments['PostId'].isin(unique_answer_ids)]\n",
    "comments_without_question_or_answer.PostId.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PostTypeId</th>\n",
       "      <th>ParentId</th>\n",
       "      <th>AcceptedAnswerId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>Body</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>LastActivityDate</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>CommentCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Id, PostTypeId, ParentId, AcceptedAnswerId, CreationDate, Score, ViewCount, Body, OwnerUserId, LastActivityDate, Title, Tags, AnswerCount, CommentCount]\n",
       "Index: []"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing this we see that the posts do not exist and that's why their comments could not inherit a topic\n",
    "posts[posts['Id'].isin(comments_without_question_or_answer.PostId.unique())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the posts dataframe with topic assignments\n",
    "#questions.to_pickle('./pickle_dataframes/questions_with_topics.pkl')\n",
    "#answers_with_topics.to_pickle('./pickle_dataframes/answers_with_topics.pkl')\n",
    "#all_comments_with_topics.to_pickle('./pickle_dataframes/comments_with_topics.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
